#!/usr/bin/env python3
"""
GitHub Data Collector (GraphQL Version)
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–±–æ—Ä–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–æ—Ä–∫–∞—Ö –∏ issues –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ GitHub GraphQL API

–≠—Ç–∞ –≤–µ—Ä—Å–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç GraphQL API –≤–º–µ—Å—Ç–æ REST API –¥–ª—è –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- Python 3.6+
- requests library
- GitHub Personal Access Token (PAT)

–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:
pip install requests

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
1. –°–æ–∑–¥–∞–π—Ç–µ PAT —Ç–æ–∫–µ–Ω –≤ GitHub (Settings ‚Üí Developer settings ‚Üí Personal access tokens)
2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è GITHUB_TOKEN –∏–ª–∏ –∏–∑–º–µ–Ω–∏—Ç–µ TOKEN –≤ —Å–∫—Ä–∏–ø—Ç–µ
3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç: python github_data_collector_graphql.py

–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ GraphQL –≤–µ—Ä—Å–∏–∏:
- –û–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
- –ë–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ API (–º–µ–Ω—å—à–µ –∑–∞–ø—Ä–æ—Å–æ–≤)
- –¢–æ—á–Ω—ã–µ –ø–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –ª–∏—à–Ω–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
- –õ—É—á—à–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –¥–∞–Ω–Ω—ã—Ö
"""

import os
import json
import csv
import time
import sys
import base64
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
import requests


@dataclass
class LicenseResult:
    repo_name: str
    success: bool
    license_type: str
    message: str
    already_had_license: bool = False
    error: Optional[str] = None


class GitHubLicenseBatchManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –º–∞—Å—Å–æ–≤–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ª–∏—Ü–µ–Ω–∑–∏–π –≤ GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏"""

    def __init__(self, token: str):
        self.token = token
        self.headers = {
            'Authorization': f'token {token}',
            'Accept': 'application/vnd.github.v3+json',
            'Content-Type': 'application/json'
        }
        self.base_url = 'https://api.github.com'
        self.session = requests.Session()
        self.session.headers.update(self.headers)

        # –î–æ—Å—Ç—É–ø–Ω—ã–µ –ª–∏—Ü–µ–Ω–∑–∏–∏
        self.available_licenses = [
            'MIT', 'Apache-2.0', 'GPL-3.0', 'GPL-2.0', 'BSD-3-Clause',
            'BSD-2-Clause', 'ISC', 'LGPL-3.0', 'LGPL-2.1', 'Unlicense'
        ]

    def get_authenticated_user(self) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏ —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        url = f'{self.base_url}/user'
        response = requests.get(url, headers=self.headers)

        if response.status_code == 200:
            user_data = response.json()
            return user_data.get('login')
        return None

    def get_user_info(self) -> Optional[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ"""
        url = f'{self.base_url}/user'
        response = requests.get(url, headers=self.headers)

        if response.status_code == 200:
            return response.json()
        return None

    def get_my_repos(self, include_forks: bool = False) -> List[Tuple[str, str, Dict]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        url = f'{self.base_url}/user/repos'
        params = {
            'type': 'all',
            'per_page': 100,
            'sort': 'updated',
            'direction': 'desc'
        }

        all_repos = []
        page = 1

        print("üîç –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤–∞—à–∏—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤...")

        while True:
            params['page'] = page
            response = requests.get(url, headers=self.headers, params=params)

            if response.status_code != 200:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {response.status_code}")
                break

            repos = response.json()
            if not repos:
                break

            for repo in repos:
                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ñ–æ—Ä–∫–æ–≤ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                if not include_forks and repo.get('fork', False):
                    continue

                all_repos.append((repo['owner']['login'], repo['name'], repo))

            print(f"üìÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page}, –Ω–∞–π–¥–µ–Ω–æ {len(repos)} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤")
            page += 1

            if page > 100:
                break

        print(f"‚úÖ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(all_repos)} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤")
        return all_repos

    def check_existing_license(self, owner: str, repo: str) -> Optional[Dict]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ª–∏—Ü–µ–Ω–∑–∏–∏ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏"""
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ API
        url = f'{self.base_url}/repos/{owner}/{repo}'
        response = requests.get(url, headers=self.headers)

        if response.status_code == 200:
            repo_data = response.json()
            api_license = repo_data.get('license')
            if api_license:
                return {
                    'source': 'api',
                    'license': api_license.get('name', 'Unknown'),
                    'key': api_license.get('key', '')
                }

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤ –ª–∏—Ü–µ–Ω–∑–∏–π
        license_files = ['LICENSE', 'LICENSE.txt', 'LICENSE.md', 'LICENCE', 'COPYING']

        for license_file in license_files:
            file_url = f'{self.base_url}/repos/{owner}/{repo}/contents/{license_file}'
            file_response = requests.get(file_url, headers=self.headers)

            if file_response.status_code == 200:
                return {
                    'source': 'file',
                    'license': 'Unknown (file exists)',
                    'file': license_file
                }

        return None

    def get_license_template(self, license_key: str) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —à–∞–±–ª–æ–Ω–∞ –ª–∏—Ü–µ–Ω–∑–∏–∏"""
        url = f'{self.base_url}/licenses/{license_key}'
        response = requests.get(url, headers=self.headers)

        if response.status_code == 200:
            return response.json()['body']
        return None

    def prepare_license_content(self, license_key: str, author_name: str = None,
                               author_email: str = None, year: int = None) -> Optional[str]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –ª–∏—Ü–µ–Ω–∑–∏–∏ —Å –∑–∞–º–µ–Ω–æ–π placeholders"""
        license_content = self.get_license_template(license_key)
        if not license_content:
            return None

        # –ó–∞–º–µ–Ω–∞ placeholders
        current_year = year or datetime.now().year

        replacements = {
            '[year]': str(current_year),
            '[yyyy]': str(current_year),
            '[fullname]': author_name or 'Author',
            '[name of copyright owner]': author_name or 'Author',
            '[email]': author_email or 'author@example.com'
        }

        for placeholder, replacement in replacements.items():
            license_content = license_content.replace(placeholder, replacement)

        return license_content

    def add_license_to_repo(self, owner: str, repo: str, license_key: str,
                           author_name: str = None, author_email: str = None,
                           force: bool = False) -> LicenseResult:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ª–∏—Ü–µ–Ω–∑–∏–∏ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π"""
        repo_full_name = f"{owner}/{repo}"

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –ª–∏—Ü–µ–Ω–∑–∏–∏
        existing_license = self.check_existing_license(owner, repo)
        if existing_license and not force:
            return LicenseResult(
                repo_name=repo_full_name,
                success=False,
                license_type=existing_license['license'],
                message=f"–õ–∏—Ü–µ–Ω–∑–∏—è —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {existing_license['license']}",
                already_had_license=True
            )

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –ª–∏—Ü–µ–Ω–∑–∏–∏
        license_content = self.prepare_license_content(license_key, author_name, author_email)
        if not license_content:
            return LicenseResult(
                repo_name=repo_full_name,
                success=False,
                license_type=license_key,
                message="–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —à–∞–±–ª–æ–Ω –ª–∏—Ü–µ–Ω–∑–∏–∏",
                error="Template not found"
            )

        # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ LICENSE
        url = f'{self.base_url}/repos/{owner}/{repo}/contents/LICENSE'

        content_encoded = base64.b64encode(license_content.encode('utf-8')).decode('utf-8')

        data = {
            'message': f'Add {license_key} license',
            'content': content_encoded,
            'committer': {
                'name': author_name or 'GitHub API',
                'email': author_email or 'noreply@github.com'
            }
        }

        response = requests.put(url, headers=self.headers, json=data)

        if response.status_code == 201:
            return LicenseResult(
                repo_name=repo_full_name,
                success=True,
                license_type=license_key,
                message="–õ–∏—Ü–µ–Ω–∑–∏—è —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–∞"
            )
        else:
            error_msg = "Unknown error"
            if response.status_code == 409:
                error_msg = "–§–∞–π–ª LICENSE —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"
            elif response.status_code == 403:
                error_msg = "–ù–µ—Ç –ø—Ä–∞–≤ –Ω–∞ –∑–∞–ø–∏—Å—å –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π"
            elif response.status_code == 404:
                error_msg = "–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω"

            return LicenseResult(
                repo_name=repo_full_name,
                success=False,
                license_type=license_key,
                message=f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ª–∏—Ü–µ–Ω–∑–∏–∏: {error_msg}",
                error=f"HTTP {response.status_code}"
            )

    def batch_add_licenses(self, license_key: str, author_name: str = None,
                          author_email: str = None, include_forks: bool = False,
                          force: bool = False, exclude_repos: List[str] = None,
                          include_only: List[str] = None) -> List[LicenseResult]:
        """–ú–∞—Å—Å–æ–≤–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ª–∏—Ü–µ–Ω–∑–∏–π –≤–æ –≤—Å–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏"""

        exclude_repos = exclude_repos or []

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
        user_info = self.get_user_info()
        if user_info and not author_name:
            author_name = user_info.get('name') or user_info.get('login')
        if user_info and not author_email:
            author_email = user_info.get('email')

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
        repos = self.get_my_repos(include_forks=include_forks)

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
        if include_only:
            repos = [(o, r, d) for o, r, d in repos if f"{o}/{r}" in include_only]

        repos = [(o, r, d) for o, r, d in repos if f"{o}/{r}" not in exclude_repos]

        if not repos:
            print("‚ùå –ù–µ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return []

        print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ª–∏—Ü–µ–Ω–∑–∏–∏ {license_key} –≤ {len(repos)} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤")
        print(f"üë§ –ê–≤—Ç–æ—Ä: {author_name}")
        print(f"üìß Email: {author_email}")
        print(f"üîÑ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {'–î–∞' if force else '–ù–µ—Ç'}")

        results = []

        for i, (owner, repo, repo_data) in enumerate(repos, 1):
            print(f"\n[{i}/{len(repos)}] –û–±—Ä–∞–±–æ—Ç–∫–∞ {owner}/{repo}...")

            # –ó–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è rate limiting
            if i > 1:
                time.sleep(1)

            result = self.add_license_to_repo(
                owner, repo, license_key, author_name, author_email, force
            )

            results.append(result)

            # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if result.success:
                print(f"‚úÖ {result.message}")
            elif result.already_had_license:
                print(f"‚ö†Ô∏è {result.message}")
            else:
                print(f"‚ùå {result.message}")

        return results

    def interactive_batch_setup(self):
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ batch –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ª–∏—Ü–µ–Ω–∑–∏–π"""
        print("üéØ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ª–∏—Ü–µ–Ω–∑–∏–π")
        print("=" * 50)

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
        user_info = self.get_user_info()
        if not user_info:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ")
            return

        username = user_info.get('login')
        user_name = user_info.get('name') or username
        user_email = user_info.get('email')

        print(f"üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {username}")
        print(f"üìù –ò–º—è: {user_name}")
        print(f"üìß Email: {user_email or '–ù–µ —É–∫–∞–∑–∞–Ω'}")

        # –í—ã–±–æ—Ä –ª–∏—Ü–µ–Ω–∑–∏–∏
        print("\nüìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –ª–∏—Ü–µ–Ω–∑–∏–∏:")
        for i, license_type in enumerate(self.available_licenses, 1):
            print(f"{i}. {license_type}")

        while True:
            try:
                choice = input(f"\n–í—ã–±–µ—Ä–∏—Ç–µ –ª–∏—Ü–µ–Ω–∑–∏—é (1-{len(self.available_licenses)}): ").strip()
                license_index = int(choice) - 1
                if 0 <= license_index < len(self.available_licenses):
                    selected_license = self.available_licenses[license_index]
                    break
                else:
                    print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")
            except ValueError:
                print("‚ùå –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ")

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–≤—Ç–æ—Ä–∞
        custom_name = input(f"\n–ò–º—è –∞–≤—Ç–æ—Ä–∞ [{user_name}]: ").strip()
        author_name = custom_name if custom_name else user_name

        custom_email = input(f"Email –∞–≤—Ç–æ—Ä–∞ [{user_email or 'noreply@github.com'}]: ").strip()
        author_email = custom_email if custom_email else (user_email or 'noreply@github.com')

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ü–∏–∏
        include_forks = input("\n–í–∫–ª—é—á–∏—Ç—å —Ñ–æ—Ä–∫–∏? (y/n) [n]: ").strip().lower() in ['y', 'yes']
        force = input("–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ª–∏—Ü–µ–Ω–∑–∏–∏? (y/n) [n]: ").strip().lower() in ['y', 'yes']

        # –ò—Å–∫–ª—é—á–µ–Ω–∏—è
        exclude_input = input("\n–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é): ").strip()
        exclude_repos = [repo.strip() for repo in exclude_input.split(',') if repo.strip()]

        # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
        print("\nüìä –ù–∞—Å—Ç—Ä–æ–π–∫–∏:")
        print(f"   –õ–∏—Ü–µ–Ω–∑–∏—è: {selected_license}")
        print(f"   –ê–≤—Ç–æ—Ä: {author_name}")
        print(f"   Email: {author_email}")
        print(f"   –í–∫–ª—é—á–∏—Ç—å —Ñ–æ—Ä–∫–∏: {'–î–∞' if include_forks else '–ù–µ—Ç'}")
        print(f"   –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {'–î–∞' if force else '–ù–µ—Ç'}")
        print(f"   –ò—Å–∫–ª—é—á–∏—Ç—å: {', '.join(exclude_repos) if exclude_repos else '–ù–µ—Ç'}")

        confirm = input("\n–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/n): ").strip().lower()
        if confirm not in ['y', 'yes']:
            print("‚ùå –û—Ç–º–µ–Ω–µ–Ω–æ")
            return

        # –ó–∞–ø—É—Å–∫ batch –æ–±—Ä–∞–±–æ—Ç–∫–∏
        results = self.batch_add_licenses(
            license_key=selected_license,
            author_name=author_name,
            author_email=author_email,
            include_forks=include_forks,
            force=force,
            exclude_repos=exclude_repos
        )

        # –û—Ç—á–µ—Ç
        self.print_batch_report(results)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        save_report = input("\nüíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á–µ—Ç –≤ —Ñ–∞–π–ª? (y/n): ").strip().lower()
        if save_report in ['y', 'yes']:
            self.save_batch_report(results, selected_license)

    def print_batch_report(self, results: List[LicenseResult]):
        """–í—ã–≤–æ–¥ –æ—Ç—á–µ—Ç–∞ –æ batch –æ–ø–µ—Ä–∞—Ü–∏–∏"""
        print("\n" + "=" * 80)
        print("üìä –û–¢–ß–ï–¢ –û –î–û–ë–ê–í–õ–ï–ù–ò–ò –õ–ò–¶–ï–ù–ó–ò–ô")
        print("=" * 80)

        successful = [r for r in results if r.success]
        already_licensed = [r for r in results if r.already_had_license]
        failed = [r for r in results if not r.success and not r.already_had_license]

        print(f"\n‚úÖ –£—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ: {len(successful)}")
        print(f"‚ö†Ô∏è –£–∂–µ –∏–º–µ–ª–∏ –ª–∏—Ü–µ–Ω–∑–∏—é: {len(already_licensed)}")
        print(f"‚ùå –û—à–∏–±–∫–∏: {len(failed)}")
        print(".1f")
        if successful:
            print("\n{'='*20} –£–°–ü–ï–®–ù–û –î–û–ë–ê–í–õ–ï–ù–û {'='*20}")
            for result in successful:
                print(f"‚úÖ {result.repo_name} - {result.license_type}")

        if already_licensed:
            print("\n{'='*20} –£–ñ–ï –ò–ú–ï–õ–ò –õ–ò–¶–ï–ù–ó–ò–Æ {'='*20}")
            for result in already_licensed:
                print(f"‚ö†Ô∏è {result.repo_name} - {result.license_type}")

        if failed:
            print("\n{'='*20} –û–®–ò–ë–ö–ò {'='*20}")
            for result in failed:
                print(f"‚ùå {result.repo_name} - {result.message}")

    def save_batch_report(self, results: List[LicenseResult], license_type: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –≤ —Ñ–∞–π–ª"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"license_batch_report_{license_type}_{timestamp}.json"

        report_data = {
            'timestamp': datetime.now().isoformat(),
            'license_type': license_type,
            'total_repos': len(results),
            'successful': len([r for r in results if r.success]),
            'already_licensed': len([r for r in results if r.already_had_license]),
            'failed': len([r for r in results if not r.success and not r.already_had_license]),
            'results': [
                {
                    'repo_name': r.repo_name,
                    'success': r.success,
                    'license_type': r.license_type,
                    'message': r.message,
                    'already_had_license': r.already_had_license,
                    'error': r.error
                }
                for r in results
            ]
        }

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)

        print(f"üíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {filename}")

    def check_topics_presence(self) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Ç–µ–≥–æ–≤ (—Ç–æ–ø–∏–∫–æ–≤) –≤–æ –≤—Å–µ—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        print("üè∑Ô∏è –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–µ–≥–æ–≤ (—Ç–æ–ø–∏–∫–æ–≤) –≤–æ –≤—Å–µ—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è—Ö...")

        # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä GitHubDataCollector –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Å —Ç–æ–ø–∏–∫–∞–º–∏ —á–µ—Ä–µ–∑ GraphQL
        collector = GitHubDataCollector(self.token)
        repos = collector.get_user_repositories()

        if not repos:
            return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏"}

        topics_status = {
            "with_topics": [],
            "without_topics": [],
            "errors": []
        }

        print(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(repos)} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤...")

        for i, repo_data in enumerate(repos, 1):
            repo_full_name = repo_data.get("nameWithOwner", "unknown/unknown")
            print(f"  {i}/{len(repos)}: {repo_full_name}")

            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ø–∏–∫–∏ —á–µ—Ä–µ–∑ GraphQL
                repository_topics = repo_data.get("repositoryTopics", {}).get("nodes", [])
                has_topics_graphql = bool(repository_topics and len(repository_topics) > 0)

                current_topics = []
                if has_topics_graphql:
                    current_topics = [node.get("topic", {}).get("name", "") for node in repository_topics]

                if has_topics_graphql:
                    topics_status["with_topics"].append({
                        "repo": repo_full_name,
                        "topics": current_topics,
                        "topics_count": len(current_topics),
                        "url": f"https://github.com/{repo_full_name}",
                        "stars": repo_data.get("stargazerCount", 0)
                    })
                else:
                    topics_status["without_topics"].append({
                        "repo": repo_full_name,
                        "url": f"https://github.com/{repo_full_name}",
                        "stars": repo_data.get("stargazerCount", 0),
                        "description": repo_data.get("description", "")
                    })

            except Exception as e:
                topics_status["errors"].append({
                    "repo": repo_full_name,
                    "error": str(e)
                })

        result = {
            "total_repos": len(repos),
            "with_topics_count": len(topics_status["with_topics"]),
            "without_topics_count": len(topics_status["without_topics"]),
            "errors_count": len(topics_status["errors"]),
            "topics_percentage": round(len(topics_status["with_topics"]) / len(repos) * 100, 1) if repos else 0,
            "details": topics_status
        }

        print("\nüè∑Ô∏è –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–†–û–í–ï–†–ö–ò –¢–ï–ì–û–í:")
        print(f"–í—Å–µ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {result['total_repos']}")
        print(f"–° —Ç–µ–≥–∞–º–∏: {result['with_topics_count']} ({result['topics_percentage']}%)")
        print(f"–ë–µ–∑ —Ç–µ–≥–æ–≤: {result['without_topics_count']}")
        print(f"–û—à–∏–±–∫–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏: {result['errors_count']}")

        return result

    def save_topics_check_to_csv(self, topics_data: Dict[str, Any], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–µ–≥–æ–≤ –≤ CSV"""
        if not topics_data or "details" not in topics_data:
            print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        details = topics_data["details"]

        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            writer.writerow(["–ê–Ω–∞–ª–∏–∑ –Ω–∞–ª–∏—á–∏—è —Ç–µ–≥–æ–≤ (—Ç–æ–ø–∏–∫–æ–≤)"])
            writer.writerow([])

            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            writer.writerow(["–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"])
            writer.writerow(["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", "–ó–Ω–∞—á–µ–Ω–∏–µ"])
            writer.writerow(["–í—Å–µ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤", topics_data.get("total_repos", 0)])
            writer.writerow(["–° —Ç–µ–≥–∞–º–∏", f"{topics_data.get('with_topics_count', 0)} ({topics_data.get('topics_percentage', 0)}%)"])
            writer.writerow(["–ë–µ–∑ —Ç–µ–≥–æ–≤", topics_data.get("without_topics_count", 0)])
            writer.writerow(["–û—à–∏–±–∫–∏", topics_data.get("errors_count", 0)])
            writer.writerow([])

            # –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ —Å —Ç–µ–≥–∞–º–∏
            if details.get("with_topics"):
                writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –° –¢–ï–ì–ê–ú–ò"])
                writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–≥–æ–≤", "–¢–µ–≥–∏", "–ó–≤–µ–∑–¥—ã", "URL"])
                for repo in sorted(details["with_topics"], key=lambda x: x.get("topics_count", 0), reverse=True):
                    topics_str = ", ".join(repo.get("topics", [])[:5])  # –û–≥—Ä–∞–Ω–∏—á–∏–º –¥–æ 5 —Ç–µ–≥–æ–≤ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                    if len(repo.get("topics", [])) > 5:
                        topics_str += f" (+{len(repo.get('topics', [])) - 5} –µ—â—ë)"
                    writer.writerow([
                        repo.get("repo", ""),
                        repo.get("topics_count", 0),
                        topics_str,
                        repo.get("stars", 0),
                        repo.get("url", "")
                    ])
                writer.writerow([])

            # –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –±–µ–∑ —Ç–µ–≥–æ–≤
            if details.get("without_topics"):
                writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ë–ï–ó –¢–ï–ì–û–í"])
                writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", "–ó–≤–µ–∑–¥—ã", "–û–ø–∏—Å–∞–Ω–∏–µ", "URL"])
                for repo in sorted(details["without_topics"], key=lambda x: x.get("stars", 0), reverse=True):
                    writer.writerow([
                        repo.get("repo", ""),
                        repo.get("stars", 0),
                        repo.get("description", "")[:50] if repo.get("description") else "",
                        repo.get("url", "")
                    ])
                writer.writerow([])

            # –û—à–∏–±–∫–∏
            if details.get("errors"):
                writer.writerow(["–û–®–ò–ë–ö–ò –ü–†–û–í–ï–†–ö–ò"])
                writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", "–û—à–∏–±–∫–∞"])
                for error in details["errors"]:
                    writer.writerow([
                        error.get("repo", ""),
                        error.get("error", "")
                    ])

        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–µ–≥–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

    def check_readme_presence(self, include_forks: bool = False) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ README —Ñ–∞–π–ª–æ–≤ –≤–æ –≤—Å–µ—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        print("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ README —Ñ–∞–π–ª–æ–≤ –≤–æ –≤—Å–µ—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è—Ö...")

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
        repos = self.get_my_repos(include_forks=include_forks)

        if not repos:
            return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏"}

        readme_status = {
            "with_readme": [],
            "without_readme": [],
            "errors": []
        }

        print(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(repos)} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤...")

        for i, (owner, repo, repo_data) in enumerate(repos, 1):
            repo_full_name = f"{owner}/{repo}"
            print(f"  {i}/{len(repos)}: {repo_full_name}")

            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º README —Ñ–∞–π–ª—ã —á–µ—Ä–µ–∑ API
                readme_files = ["README.md", "README.rst", "README.txt", "README", "readme.md", "Readme.md"]
                has_readme = False
                readme_found = None

                for readme_file in readme_files:
                    readme_url = f"https://api.github.com/repos/{owner}/{repo}/contents/{readme_file}"
                    readme_response = self.session.get(readme_url)
                    if readme_response.status_code == 200:
                        has_readme = True
                        readme_found = readme_file
                        break

                if has_readme:
                    readme_status["with_readme"].append({
                        "repo": repo_full_name,
                        "readme_file": readme_found,
                        "url": f"https://github.com/{repo_full_name}",
                        "stars": repo_data.get("stargazerCount", 0)
                    })
                else:
                    readme_status["without_readme"].append({
                        "repo": repo_full_name,
                        "url": f"https://github.com/{repo_full_name}",
                        "stars": repo_data.get("stargazerCount", 0),
                        "description": repo_data.get("description", "")
                    })

            except Exception as e:
                readme_status["errors"].append({
                    "repo": repo_full_name,
                    "error": str(e)
                })

        result = {
            "total_repos": len(repos),
            "with_readme_count": len(readme_status["with_readme"]),
            "without_readme_count": len(readme_status["without_readme"]),
            "errors_count": len(readme_status["errors"]),
            "readme_percentage": round(len(readme_status["with_readme"]) / len(repos) * 100, 1) if repos else 0,
            "details": readme_status
        }

        print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–†–û–í–ï–†–ö–ò README:")
        print(f"–í—Å–µ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {result['total_repos']}")
        print(f"–° README: {result['with_readme_count']} ({result['readme_percentage']}%)")
        print(f"–ë–µ–∑ README: {result['without_readme_count']}")
        print(f"–û—à–∏–±–∫–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏: {result['errors_count']}")

        return result

    def save_readme_check_to_csv(self, readme_data: Dict[str, Any], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ README –≤ CSV"""
        if not readme_data or "details" not in readme_data:
            print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        details = readme_data["details"]

        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            writer.writerow(["–ê–Ω–∞–ª–∏–∑ –Ω–∞–ª–∏—á–∏—è README —Ñ–∞–π–ª–æ–≤"])
            writer.writerow([])

            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            writer.writerow(["–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"])
            writer.writerow(["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", "–ó–Ω–∞—á–µ–Ω–∏–µ"])
            writer.writerow(["–í—Å–µ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤", readme_data.get("total_repos", 0)])
            writer.writerow(["–° README", f"{readme_data.get('with_readme_count', 0)} ({readme_data.get('readme_percentage', 0)}%)"])
            writer.writerow(["–ë–µ–∑ README", readme_data.get("without_readme_count", 0)])
            writer.writerow(["–û—à–∏–±–∫–∏", readme_data.get("errors_count", 0)])
            writer.writerow([])

            # –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ —Å README
            if details.get("with_readme"):
                writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –° README"])
                writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", "–§–∞–π–ª README", "–ó–≤–µ–∑–¥—ã", "URL"])
                for repo in sorted(details["with_readme"], key=lambda x: x.get("stars", 0), reverse=True):
                    writer.writerow([
                        repo.get("repo", ""),
                        repo.get("readme_file", ""),
                        repo.get("stars", 0),
                        repo.get("url", "")
                    ])
                writer.writerow([])

            # –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –±–µ–∑ README
            if details.get("without_readme"):
                writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ë–ï–ó README"])
                writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", "–ó–≤–µ–∑–¥—ã", "–û–ø–∏—Å–∞–Ω–∏–µ", "URL"])
                for repo in sorted(details["without_readme"], key=lambda x: x.get("stars", 0), reverse=True):
                    writer.writerow([
                        repo.get("repo", ""),
                        repo.get("stars", 0),
                        repo.get("description", "")[:50] if repo.get("description") else "",
                        repo.get("url", "")
                    ])
                writer.writerow([])

            # –û—à–∏–±–∫–∏
            if details.get("errors"):
                writer.writerow(["–û–®–ò–ë–ö–ò –ü–†–û–í–ï–†–ö–ò"])
                writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", "–û—à–∏–±–∫–∞"])
                for error in details["errors"]:
                    writer.writerow([
                        error.get("repo", ""),
                        error.get("error", "")
                    ])

        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ README —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")


class GitHubDataCollector:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ GitHub API"""

    def __init__(self, token: str, username: str = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–∞

        Args:
            token: GitHub Personal Access Token
            username: –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è GitHub (–µ—Å–ª–∏ None, –±—É–¥–µ—Ç –ø–æ–ª—É—á–µ–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
        """
        self.token = token
        self.username = username
        self.base_url = "https://api.github.com"
        self.session = requests.Session()

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–µ—Å—Å–∏–∏
        self.session.headers.update({
            "Authorization": f"Bearer {token}",
            "Accept": "application/vnd.github+json",
            "X-GitHub-Api-Version": "2022-11-28",
            "User-Agent": "GitHub-Data-Collector-GraphQL/1.0"
        })

        # –ü–æ–ª—É—á–∞–µ–º username –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω
        if not self.username:
            self.username = self._get_current_user()

    def _get_current_user(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–º—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        response = self.session.get(f"{self.base_url}/user")
        response.raise_for_status()
        return response.json()["login"]

    def _make_request(self, url: str, params: Dict = None) -> Dict:
        """
        –°–¥–µ–ª–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∫ API —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –∏ rate limiting

        Args:
            url: URL –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞

        Returns:
            JSON –æ—Ç–≤–µ—Ç –æ—Ç API
        """
        while True:
            response = self.session.get(url, params=params)

            if response.status_code == 200:
                return response.json()
            elif response.status_code == 403:
                # Rate limit –∏–ª–∏ –¥—Ä—É–≥–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
                reset_time = int(response.headers.get("X-RateLimit-Reset", 0))
                wait_time = max(reset_time - time.time(), 60)  # –ú–∏–Ω–∏–º—É–º 60 —Å–µ–∫—É–Ω–¥
                print(f"Rate limit exceeded. Waiting {wait_time:.0f} seconds...")
                time.sleep(wait_time)
                continue
            else:
                response.raise_for_status()

    def _make_graphql_request(self, query: str, variables: Dict = None) -> Dict:
        """
        –°–¥–µ–ª–∞—Ç—å GraphQL –∑–∞–ø—Ä–æ—Å —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –∏ rate limiting

        Args:
            query: GraphQL –∑–∞–ø—Ä–æ—Å
            variables: –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞

        Returns:
            JSON –æ—Ç–≤–µ—Ç –æ—Ç GraphQL API
        """
        while True:
            payload = {"query": query}
            if variables:
                payload["variables"] = variables

            response = self.session.post(
                f"{self.base_url}/graphql",
                json=payload
            )

            if response.status_code == 200:
                result = response.json()
                if "errors" in result:
                    raise Exception(f"GraphQL errors: {result['errors']}")
                return result["data"]
            elif response.status_code == 403:
                # Rate limit –∏–ª–∏ –¥—Ä—É–≥–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
                reset_time = int(response.headers.get("X-RateLimit-Reset", 0))
                wait_time = max(reset_time - time.time(), 60)  # –ú–∏–Ω–∏–º—É–º 60 —Å–µ–∫—É–Ω–¥
                print(f"Rate limit exceeded. Waiting {wait_time:.0f} seconds...")
                time.sleep(wait_time)
                continue
            else:
                response.raise_for_status()

    def get_all_forks(self) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Ñ–æ—Ä–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ GraphQL

        Returns:
            –°–ø–∏—Å–æ–∫ —Ñ–æ—Ä–∫–æ–≤ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–∞–∂–¥–æ–º
        """
        print("–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ñ–æ—Ä–∫–æ–≤ —á–µ—Ä–µ–∑ GraphQL...")

        forks = []
        cursor = None

        while True:
            query = """
            query($username: String!, $after: String) {
              user(login: $username) {
                repositories(
                  first: 100,
                  isFork: true,
                  orderBy: {field: CREATED_AT, direction: ASC},
                  after: $after
                ) {
                  nodes {
                    name
                    nameWithOwner
                    url
                    createdAt
                    pushedAt
                    updatedAt
                    description
                    primaryLanguage {
                      name
                    }
                    forkCount
                    stargazerCount
                    parent {
                      nameWithOwner
                      url
                    }
                  }
                  pageInfo {
                    hasNextPage
                    endCursor
                  }
                }
              }
            }
            """

            variables = {
                "username": self.username,
                "after": cursor
            }

            result = self._make_graphql_request(query, variables)

            if not result.get("user") or not result["user"].get("repositories"):
                break

            repos = result["user"]["repositories"]
            page_forks = repos["nodes"]
            forks.extend(page_forks)

            print(f"–ü–æ—Ä—Ü–∏—è: –Ω–∞–π–¥–µ–Ω–æ {len(page_forks)} —Ñ–æ—Ä–∫–æ–≤ (–≤—Å–µ–≥–æ: {len(forks)})")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –µ—â–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if not repos["pageInfo"]["hasNextPage"]:
                break

            cursor = repos["pageInfo"]["endCursor"]

        print(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —Ñ–æ—Ä–∫–æ–≤: {len(forks)}")
        return forks

    def get_all_issues(self) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ issues –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ GraphQL (–≤–∫–ª—é—á–∞—è –∑–∞–∫—Ä—ã—Ç—ã–µ)

        Returns:
            –°–ø–∏—Å–æ–∫ issues —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–∞–∂–¥–æ–º
        """
        print("–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ issues —á–µ—Ä–µ–∑ GraphQL...")

        issues = []
        cursor = None

        while True:
            query = """
            query($username: String!, $after: String) {
              user(login: $username) {
                issues(
                  first: 100,
                  orderBy: {field: CREATED_AT, direction: ASC},
                  states: [OPEN, CLOSED],
                  after: $after
                ) {
                  nodes {
                    title
                    url
                    state
                    createdAt
                    closedAt
                    updatedAt
                    comments {
                      totalCount
                    }
                    labels(first: 10) {
                      nodes {
                        name
                      }
                    }
                    repository {
                      nameWithOwner
                      url
                    }
                  }
                  pageInfo {
                    hasNextPage
                    endCursor
                  }
                }
              }
            }
            """

            variables = {
                "username": self.username,
                "after": cursor
            }

            result = self._make_graphql_request(query, variables)

            if not result.get("user") or not result["user"].get("issues"):
                break

            user_issues = result["user"]["issues"]
            page_issues = user_issues["nodes"]
            issues.extend(page_issues)

            print(f"–ü–æ—Ä—Ü–∏—è: –Ω–∞–π–¥–µ–Ω–æ {len(page_issues)} issues (–≤—Å–µ–≥–æ: {len(issues)})")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –µ—â–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if not user_issues["pageInfo"]["hasNextPage"]:
                break

            cursor = user_issues["pageInfo"]["endCursor"]

        print(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ issues: {len(issues)}")
        return issues

    def save_to_json(self, data: Dict[str, Any], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ JSON —Ñ–∞–π–ª"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        print(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

    def save_forks_to_csv(self, forks: List[Dict[str, Any]], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–æ—Ä–∫–∏ –≤ CSV —Ñ–∞–π–ª (GraphQL —Ñ–æ—Ä–º–∞—Ç)"""
        if not forks:
            print("–ù–µ—Ç —Ñ–æ—Ä–∫–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        fieldnames = [
            'name', 'nameWithOwner', 'createdAt', 'pushedAt', 'updatedAt',
            'url', 'description', 'primaryLanguage', 'forkCount', 'stargazerCount',
            'parent_nameWithOwner', 'parent_url'
        ]

        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()

            for fork in forks:
                parent = fork.get('parent', {})
                primary_language = fork.get('primaryLanguage', {})

                row = {
                    'name': fork.get('name', ''),
                    'nameWithOwner': fork.get('nameWithOwner', ''),
                    'createdAt': fork.get('createdAt', ''),
                    'pushedAt': fork.get('pushedAt', ''),
                    'updatedAt': fork.get('updatedAt', ''),
                    'url': fork.get('url', ''),
                    'description': fork.get('description', ''),
                    'primaryLanguage': primary_language.get('name', '') if primary_language else '',
                    'forkCount': fork.get('forkCount', 0),
                    'stargazerCount': fork.get('stargazerCount', 0),
                    'parent_nameWithOwner': parent.get('nameWithOwner', ''),
                    'parent_url': parent.get('url', '')
                }
                writer.writerow(row)

        print(f"–§–æ—Ä–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

    def save_issues_to_csv(self, issues: List[Dict[str, Any]], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å issues –≤ CSV —Ñ–∞–π–ª (GraphQL —Ñ–æ—Ä–º–∞—Ç)"""
        if not issues:
            print("–ù–µ—Ç issues –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        fieldnames = [
            'title', 'state', 'createdAt', 'closedAt', 'updatedAt',
            'url', 'repository_nameWithOwner', 'repository_url',
            'comments_totalCount', 'labels'
        ]

        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()

            for issue in issues:
                repo = issue.get('repository', {})
                comments = issue.get('comments', {})
                labels_data = issue.get('labels', {}).get('nodes', [])
                labels = [label['name'] for label in labels_data]

                row = {
                    'title': issue.get('title', ''),
                    'state': issue.get('state', ''),
                    'createdAt': issue.get('createdAt', ''),
                    'closedAt': issue.get('closedAt', ''),
                    'updatedAt': issue.get('updatedAt', ''),
                    'url': issue.get('url', ''),
                    'repository_nameWithOwner': repo.get('nameWithOwner', ''),
                    'repository_url': repo.get('url', ''),
                    'comments_totalCount': comments.get('totalCount', 0) if comments else 0,
                    'labels': '; '.join(labels)
                }
                writer.writerow(row)

        print(f"Issues —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

    def get_user_profile_stats(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è "—Ä–∞—Å–∫–∞—á–∫–∏" –∞–∫–∫–∞—É–Ω—Ç–∞

        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ—Ñ–∏–ª—è
        """
        print("–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ—Ñ–∏–ª—è...")

        query = """
        query($username: String!) {
          user(login: $username) {
            login
            name
            bio
            company
            location
            websiteUrl
            email
            twitterUsername
            createdAt
            updatedAt
            followers {
              totalCount
            }
            following {
              totalCount
            }
            repositories {
              totalCount
            }
            repositoriesContributedTo(first: 1, contributionTypes: [COMMIT, ISSUE, PULL_REQUEST, REPOSITORY]) {
              totalCount
            }
            starredRepositories {
              totalCount
            }
            issues(first: 1, states: [OPEN, CLOSED]) {
              totalCount
            }
            pullRequests(first: 1, states: [OPEN, CLOSED, MERGED]) {
              totalCount
            }
            contributionsCollection {
              totalCommitContributions
              totalIssueContributions
              totalPullRequestContributions
              totalPullRequestReviewContributions
              totalRepositoryContributions
              totalCommitContributions
              restrictedContributionsCount
              contributionCalendar {
                totalContributions
                weeks {
                  contributionDays {
                    contributionCount
                    date
                  }
                }
              }
            }
          }
        }
        """

        variables = {"username": self.username}
        result = self._make_graphql_request(query, variables)

        if not result.get("user"):
            return {}

        user = result["user"]

        # –ê–Ω–∞–ª–∏–∑ —è–∑—ã–∫–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
        languages = self._get_user_languages()

        # –ê–Ω–∞–ª–∏–∑ —Ç–æ–ø —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
        top_repos = self._get_top_repositories()

        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        activity_trends = self._analyze_activity_trends(user.get("contributionsCollection", {}))

        profile_stats = {
            "basic_info": {
                "login": user.get("login"),
                "name": user.get("name"),
                "bio": user.get("bio"),
                "company": user.get("company"),
                "location": user.get("location"),
                "website": user.get("websiteUrl"),
                "email": user.get("email"),
                "twitter": user.get("twitterUsername"),
                "created_at": user.get("createdAt"),
                "updated_at": user.get("updatedAt")
            },
            "social_stats": {
                "followers": user.get("followers", {}).get("totalCount", 0),
                "following": user.get("following", {}).get("totalCount", 0),
                "repositories": user.get("repositories", {}).get("totalCount", 0),
                "starred_repos": user.get("starredRepositories", {}).get("totalCount", 0),
                "contributed_to": user.get("repositoriesContributedTo", {}).get("totalCount", 0)
            },
            "contribution_stats": {
                "total_issues": user.get("issues", {}).get("totalCount", 0),
                "total_pull_requests": user.get("pullRequests", {}).get("totalCount", 0),
                "total_commits": user.get("contributionsCollection", {}).get("totalCommitContributions", 0),
                "total_issue_contributions": user.get("contributionsCollection", {}).get("totalIssueContributions", 0),
                "total_pr_contributions": user.get("contributionsCollection", {}).get("totalPullRequestContributions", 0),
                "total_pr_review_contributions": user.get("contributionsCollection", {}).get("totalPullRequestReviewContributions", 0),
                "total_repo_contributions": user.get("contributionsCollection", {}).get("totalRepositoryContributions", 0),
                "total_contributions_this_year": user.get("contributionsCollection", {}).get("contributionCalendar", {}).get("totalContributions", 0)
            },
            "languages": languages,
            "top_repositories": top_repos,
            "activity_trends": activity_trends
        }

        print("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—É—á–µ–Ω–∞")
        return profile_stats

    def _get_user_languages(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —è–∑—ã–∫–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        print("–ê–Ω–∞–ª–∏–∑ —è–∑—ã–∫–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è...")

        query = """
        query($username: String!) {
          user(login: $username) {
            repositories(first: 100, isFork: false, orderBy: {field: STARGAZERS, direction: DESC}) {
              nodes {
                primaryLanguage {
                  name
                }
                languages(first: 10, orderBy: {field: SIZE, direction: DESC}) {
                  edges {
                    size
                    node {
                      name
                    }
                  }
                  totalSize
                }
              }
            }
          }
        }
        """

        variables = {"username": self.username}
        result = self._make_graphql_request(query, variables)

        languages_stats = {}
        total_size = 0

        if result.get("user") and result["user"].get("repositories"):
            for repo in result["user"]["repositories"]["nodes"]:
                if repo.get("languages"):
                    for lang in repo["languages"]["edges"]:
                        lang_name = lang["node"]["name"]
                        lang_size = lang["size"]

                        if lang_name in languages_stats:
                            languages_stats[lang_name] += lang_size
                        else:
                            languages_stats[lang_name] = lang_size

                        total_size += lang_size

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –ø—Ä–æ—Ü–µ–Ω—Ç—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
        languages_percent = {}
        for lang, size in languages_stats.items():
            languages_percent[lang] = round((size / total_size * 100), 1) if total_size > 0 else 0

        sorted_languages = dict(sorted(languages_percent.items(), key=lambda x: x[1], reverse=True))

        return {
            "by_percentage": sorted_languages,
            "by_bytes": dict(sorted(languages_stats.items(), key=lambda x: x[1], reverse=True)),
            "total_languages": len(sorted_languages)
        }

    def _get_top_repositories(self) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–æ–ø —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –ø–æ –∑–≤–µ–∑–¥–∞–º –∏ —Ñ–æ—Ä–∫–∞–º"""
        print("–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–ø —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤...")

        query = """
        query($username: String!) {
          user(login: $username) {
            topRepositories(first: 10, orderBy: {field: STARGAZERS, direction: DESC}) {
              nodes {
                nameWithOwner
                description
                url
                stargazerCount
                forkCount
                primaryLanguage {
                  name
                }
                createdAt
                updatedAt
                isArchived
                isFork
              }
            }
          }
        }
        """

        variables = {"username": self.username}
        result = self._make_graphql_request(query, variables)

        top_repos = []
        if result.get("user") and result["user"].get("topRepositories"):
            for repo in result["user"]["topRepositories"]["nodes"]:
                if not repo.get("isFork"):  # –¢–æ–ª—å–∫–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
                    top_repos.append({
                        "name": repo.get("nameWithOwner"),
                        "description": repo.get("description"),
                        "url": repo.get("url"),
                        "stars": repo.get("stargazerCount", 0),
                        "forks": repo.get("forkCount", 0),
                        "language": repo.get("primaryLanguage", {}).get("name") if repo.get("primaryLanguage") else None,
                        "created_at": repo.get("createdAt"),
                        "updated_at": repo.get("updatedAt"),
                        "is_archived": repo.get("isArchived", False)
                    })

        return top_repos

    def _analyze_activity_trends(self, contributions: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
        calendar = contributions.get("contributionCalendar", {})
        weeks = calendar.get("weeks", [])

        # –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 52 –Ω–µ–¥–µ–ª—å (–≥–æ–¥)
        recent_weeks = weeks[-52:] if len(weeks) > 52 else weeks

        weekly_contributions = []
        monthly_contributions = {}
        daily_patterns = {i: 0 for i in range(7)}  # 0-6: –ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫-–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ

        total_contributions = 0
        active_days = 0
        max_daily = 0

        for week in recent_weeks:
            week_total = 0
            for day in week.get("contributionDays", []):
                count = day.get("contributionCount", 0)
                date_str = day.get("date", "")

                if count > 0:
                    active_days += 1
                    total_contributions += count
                    week_total += count
                    max_daily = max(max_daily, count)

                # –ê–Ω–∞–ª–∏–∑ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏ (0 = –ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫, 6 = –í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ)
                if date_str:
                    try:
                        date_obj = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                        weekday = date_obj.weekday()  # 0 = –ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫
                        daily_patterns[weekday] += count
                    except:
                        pass

                # –ê–Ω–∞–ª–∏–∑ –ø–æ –º–µ—Å—è—Ü–∞–º
                if date_str:
                    try:
                        month_key = date_str[:7]  # YYYY-MM
                        if month_key in monthly_contributions:
                            monthly_contributions[month_key] += count
                        else:
                            monthly_contributions[month_key] = count
                    except:
                        pass

            weekly_contributions.append(week_total)

        # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–π –∞–∫—Ç–∏–≤–Ω—ã–π –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏
        most_active_day = max(daily_patterns.items(), key=lambda x: x[1])[0]
        day_names = ["–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–í—Ç–æ—Ä–Ω–∏–∫", "–°—Ä–µ–¥–∞", "–ß–µ—Ç–≤–µ—Ä–≥", "–ü—è—Ç–Ω–∏—Ü–∞", "–°—É–±–±–æ—Ç–∞", "–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"]

        # –°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        avg_weekly = sum(weekly_contributions) / len(weekly_contributions) if weekly_contributions else 0
        avg_daily = total_contributions / len(recent_weeks) / 7 if recent_weeks else 0

        return {
            "total_contributions_last_year": total_contributions,
            "active_days_last_year": active_days,
            "average_weekly_contributions": round(avg_weekly, 1),
            "average_daily_contributions": round(avg_daily, 1),
            "max_daily_contributions": max_daily,
            "most_active_day": day_names[most_active_day] if most_active_day < len(day_names) else "Unknown",
            "monthly_contributions": dict(sorted(monthly_contributions.items())),
            "consistency_score": round((active_days / (len(recent_weeks) * 7)) * 100, 1) if recent_weeks else 0
        }

    def get_user_repositories(self) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–Ω–µ —Ñ–æ—Ä–∫–∏)

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
        """
        print("–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è...")

        repositories = []
        cursor = None

        while True:
            query = """
            query($username: String!, $after: String) {
              user(login: $username) {
                repositories(
                  first: 100,
                  isFork: false,
                  orderBy: {field: CREATED_AT, direction: DESC},
                  after: $after
                ) {
                  nodes {
                    name
                    nameWithOwner
                    url
                    createdAt
                    description
                    forkCount
                    stargazerCount
                    repositoryTopics(first: 10) {
                      nodes {
                        topic {
                          name
                        }
                      }
                    }
                  }
                  pageInfo {
                    hasNextPage
                    endCursor
                  }
                }
              }
            }
            """

            variables = {
                "username": self.username,
                "after": cursor
            }

            result = self._make_graphql_request(query, variables)

            if not result.get("user") or not result["user"].get("repositories"):
                break

            repos = result["user"]["repositories"]
            page_repos = repos["nodes"]
            repositories.extend(page_repos)

            print(f"–ü–æ—Ä—Ü–∏—è: –Ω–∞–π–¥–µ–Ω–æ {len(page_repos)} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ (–≤—Å–µ–≥–æ: {len(repositories)})")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –µ—â–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if not repos["pageInfo"]["hasNextPage"]:
                break

            cursor = repos["pageInfo"]["endCursor"]

        print(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {len(repositories)}")
        return repositories

    def get_repositories_stars_sorted(self) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∑–≤–µ–∑–¥

        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ –∑–≤–µ–∑–¥–∞–º (–æ—Ç –±–æ–ª—å—à–µ–≥–æ –∫ –º–µ–Ω—å—à–µ–º—É)
        """
        print("–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ –∑–≤–µ–∑–¥–∞–º...")

        repositories = []
        cursor = None

        max_pages = 5  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏ API
        page_count = 0

        while page_count < max_pages:
            # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è 502 –æ—à–∏–±–∫–∏
            query = """
            query($username: String!, $after: String) {
              user(login: $username) {
                repositories(
                  first: 30,  # –£–º–µ–Ω—å—à–∏–ª–∏ —Ä–∞–∑–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                  isFork: false,
                  orderBy: {field: STARGAZERS, direction: DESC},
                  after: $after
                ) {
                  nodes {
                    name
                    nameWithOwner
                    url
                    createdAt
                    description
                    primaryLanguage {
                      name
                    }
                    forkCount
                    stargazerCount
                    isArchived
                    diskUsage
                  }
                  pageInfo {
                    hasNextPage
                    endCursor
                  }
                }
              }
            }
            """

            variables = {
                "username": self.username,
                "after": cursor
            }

            try:
                result = self._make_graphql_request(query, variables)

                if not result.get("user") or not result["user"].get("repositories"):
                    break

                repos = result["user"]["repositories"]
                page_repos = repos["nodes"]
                repositories.extend(page_repos)

                print(f"–ü–æ—Ä—Ü–∏—è {page_count + 1}: –Ω–∞–π–¥–µ–Ω–æ {len(page_repos)} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ (–≤—Å–µ–≥–æ: {len(repositories)})")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –µ—â–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                if not repos["pageInfo"]["hasNextPage"]:
                    break

                cursor = repos["pageInfo"]["endCursor"]
                page_count += 1

                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                time.sleep(0.5)

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_count + 1}: {e}")
                break

        print(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {len(repositories)}")

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∑–≤–µ–∑–¥ (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π, —Ö–æ—Ç—è GraphQL —É–∂–µ —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç)
        repositories.sort(key=lambda x: x.get('stargazerCount', 0), reverse=True)

        return repositories

    def save_repositories_stars_to_csv(self, repositories: List[Dict[str, Any]], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –∑–≤–µ–∑–¥–∞–º –≤ CSV"""
        if not repositories:
            print("–ù–µ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)

            writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –∑–≤–µ–∑–¥–∞–º (‚≠ê)"])
            writer.writerow([])
            writer.writerow(["–†–µ–π—Ç–∏–Ω–≥", "–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", "–ó–≤–µ–∑–¥—ã", "–§–æ—Ä–∫–∏", "–Ø–∑—ã–∫", "–°–æ–∑–¥–∞–Ω", "–û–±–Ω–æ–≤–ª–µ–Ω", "–ê—Ä—Ö–∏–≤", "–ü—Ä–∏–≤–∞—Ç–Ω—ã–π", "–†–∞–∑–º–µ—Ä (KB)", "Issues", "PRs", "Releases", "–û–ø–∏—Å–∞–Ω–∏–µ"])
            writer.writerow([])

            for i, repo in enumerate(repositories, 1):
                primary_language = repo.get('primaryLanguage', {})
                issues = repo.get('issues', {})
                pull_requests = repo.get('pullRequests', {})
                releases = repo.get('releases', {})

                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–∞–∑–º–µ—Ä –∏–∑ –±–∞–π—Ç–æ–≤ –≤ KB
                disk_usage_kb = round(repo.get('diskUsage', 0) / 1024, 1) if repo.get('diskUsage') else 0

                writer.writerow([
                    f"#{i}",
                    repo.get('nameWithOwner', ''),
                    repo.get('stargazerCount', 0),
                    repo.get('forkCount', 0),
                    primary_language.get('name', '') if primary_language else '',
                    repo.get('createdAt', '')[:10] if repo.get('createdAt') else '',
                    repo.get('updatedAt', '')[:10] if repo.get('updatedAt') else '',
                    "–î–∞" if repo.get('isArchived') else "–ù–µ—Ç",
                    "–î–∞" if repo.get('isPrivate') else "–ù–µ—Ç",
                    disk_usage_kb,
                    issues.get('totalCount', 0) if issues else 0,
                    pull_requests.get('totalCount', 0) if pull_requests else 0,
                    releases.get('totalCount', 0) if releases else 0,
                    (repo.get('description', '') or '')[:100]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ 100 —Å–∏–º–≤–æ–ª–∞–º–∏
                ])

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤ –∫–æ–Ω—Ü–µ —Ñ–∞–π–ª–∞
            writer.writerow([])
            writer.writerow(["=== –°–¢–ê–¢–ò–°–¢–ò–ö–ê ==="])

            total_stars = sum(repo.get('stargazerCount', 0) for repo in repositories)
            total_forks = sum(repo.get('forkCount', 0) for repo in repositories)
            total_size = sum(repo.get('diskUsage', 0) for repo in repositories) / 1024 / 1024  # –≤ MB

            writer.writerow(["–í—Å–µ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤", len(repositories)])
            writer.writerow(["–í—Å–µ–≥–æ –∑–≤–µ–∑–¥", total_stars])
            writer.writerow(["–í—Å–µ–≥–æ —Ñ–æ—Ä–∫–æ–≤", total_forks])
            writer.writerow(["–°—Ä–µ–¥–Ω–µ–µ –∑–≤–µ–∑–¥ –Ω–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", round(total_stars / len(repositories), 2) if repositories else 0])
            writer.writerow(["–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤", f"{round(total_size, 2)} MB"])

            # –¢–æ–ø –ø–æ –∑–≤–µ–∑–¥–∞–º
            if repositories:
                top_repo = repositories[0]
                writer.writerow(["–¢–æ–ø —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –ø–æ –∑–≤–µ–∑–¥–∞–º", f"{top_repo.get('nameWithOwner')} ({top_repo.get('stargazerCount', 0)} ‚≠ê)"])

            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —è–∑—ã–∫–∞–º
            writer.writerow([])
            writer.writerow(["=== –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –Ø–ó–´–ö–ê–ú ==="])

            languages = {}
            for repo in repositories:
                lang = repo.get('primaryLanguage', {}).get('name', 'Unknown') if repo.get('primaryLanguage') else 'Unknown'
                languages[lang] = languages.get(lang, 0) + 1

            sorted_languages = sorted(languages.items(), key=lambda x: x[1], reverse=True)
            for lang, count in sorted_languages[:10]:  # –¢–æ–ø 10 —è–∑—ã–∫–æ–≤
                writer.writerow([lang, count])

        print(f"–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ø–æ –∑–≤–µ–∑–¥–∞–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

    def get_repository_analytics(self, repo_name: str) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é

        Args:
            repo_name: –ü–æ–ª–Ω–æ–µ –∏–º—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è (owner/name)

        Returns:
            –î–µ—Ç–∞–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
        """
        print(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –¥–ª—è {repo_name}...")

        # –†–∞–∑–±–∏—Ä–∞–µ–º owner/name
        try:
            owner, name = repo_name.split('/', 1)
        except ValueError:
            return {"error": f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è: {repo_name}"}

        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏ API
        query = """
        query($owner: String!, $name: String!) {
          repository(owner: $owner, name: $name) {
            nameWithOwner
            description
            createdAt
            updatedAt
            pushedAt
            isArchived
            isPrivate
            isFork
            forkCount
            stargazerCount
            watchers {
              totalCount
            }
            primaryLanguage {
              name
            }
            languages(first: 5, orderBy: {field: SIZE, direction: DESC}) {
              totalSize
              edges {
                size
                node {
                  name
                }
              }
            }
            diskUsage
            issues(states: [OPEN, CLOSED]) {
              totalCount
            }
            pullRequests(states: [OPEN, CLOSED, MERGED]) {
              totalCount
            }
            releases {
              totalCount
            }
            licenseInfo {
              name
            }
            repositoryTopics(first: 5) {
              nodes {
                topic {
                  name
                }
              }
            }
          }
        }
        """

        variables = {"owner": owner, "name": name}

        try:
            result = self._make_graphql_request(query, variables)

            if not result.get("repository"):
                return {"error": f"–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π {repo_name} –Ω–µ –Ω–∞–π–¥–µ–Ω"}

            repo = result["repository"]

            # –†–∞—Å—á–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
            analytics = {
                "basic_info": {
                    "name": repo.get("nameWithOwner"),
                    "description": repo.get("description"),
                    "created_at": repo.get("createdAt"),
                    "updated_at": repo.get("updatedAt"),
                    "pushed_at": repo.get("pushedAt"),
                    "is_archived": repo.get("isArchived"),
                    "is_private": repo.get("isPrivate"),
                    "is_fork": repo.get("isFork")
                },
                "popularity": {
                    "stars": repo.get("stargazerCount", 0),
                    "forks": repo.get("forkCount", 0),
                    "watchers": repo.get("watchers", {}).get("totalCount", 0)
                },
                "activity": {
                    "total_commits": repo.get("defaultBranchRef", {}).get("target", {}).get("history", {}).get("totalCount", 0),
                    "issues_total": repo.get("issues", {}).get("totalCount", 0),
                    "pull_requests_total": repo.get("pullRequests", {}).get("totalCount", 0),
                    "releases_total": repo.get("releases", {}).get("totalCount", 0),
                    "tags_total": repo.get("tags", {}).get("totalCount", 0)
                },
                "technical": {
                    "primary_language": repo.get("primaryLanguage", {}).get("name") if repo.get("primaryLanguage") else None,
                    "disk_usage_kb": round(repo.get("diskUsage", 0) / 1024, 1) if repo.get("diskUsage") else 0,
                    "license": repo.get("licenseInfo", {}).get("name") if repo.get("licenseInfo") else None,
                    "collaborators": repo.get("collaborators", {}).get("totalCount", 0),
                    "contributors": repo.get("mentionableUsers", {}).get("totalCount", 0),
                    "vulnerabilities": repo.get("vulnerabilityAlerts", {}).get("totalCount", 0)
                },
                "topics": [node["topic"]["name"] for node in repo.get("repositoryTopics", {}).get("nodes", [])],
                "languages": self._analyze_repo_languages(repo.get("languages", {}))
            }

            # –†–∞—Å—á–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
            analytics["ratios"] = {
                "forks_to_stars_ratio": round(repo.get("forkCount", 0) / max(repo.get("stargazerCount", 1), 1), 2),
                "issues_to_stars_ratio": round(repo.get("issues", {}).get("totalCount", 0) / max(repo.get("stargazerCount", 1), 1), 2),
                "activity_score": round((repo.get("stargazerCount", 0) + repo.get("forkCount", 0) + repo.get("watchers", {}).get("totalCount", 0)) / max(repo.get("diskUsage", 1), 1) * 1000, 2)
            }

            # –í–æ–∑—Ä–∞—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞
            if repo.get("createdAt"):
                created_date = datetime.fromisoformat(repo["createdAt"].replace('Z', '+00:00'))
                now = datetime.now(created_date.tzinfo)
                age_days = (now - created_date).days
                analytics["age"] = {
                    "days": age_days,
                    "months": round(age_days / 30, 1),
                    "years": round(age_days / 365, 1)
                }

            return analytics

        except Exception as e:
            return {"error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –¥–ª—è {repo_name}: {str(e)}"}

    def _analyze_repo_languages(self, languages_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —è–∑—ã–∫–æ–≤ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
        if not languages_data:
            return {"languages": {}, "total_size": 0}

        languages = {}
        total_size = languages_data.get("totalSize", 0)

        for edge in languages_data.get("edges", []):
            lang_name = edge["node"]["name"]
            lang_size = edge["size"]
            languages[lang_name] = {
                "bytes": lang_size,
                "percentage": round((lang_size / total_size * 100), 1) if total_size > 0 else 0
            }

        return {
            "languages": languages,
            "total_size": total_size,
            "total_size_kb": round(total_size / 1024, 1)
        }

    def get_top_repositories_analytics(self, repos_list: List[Dict[str, Any]], limit: int = None, batch_size: int = 3) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤

        Args:
            repos_list: –°–ø–∏—Å–æ–∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ (None = –≤—Å–µ –∏–∑ —Å–ø–∏—Å–∫–∞)
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–º–µ–Ω—å—à–µ = –º–µ–Ω—å—à–µ –Ω–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ API)

        Returns:
            –°–ø–∏—Å–æ–∫ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
        """
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        if limit is None:
            repos_to_analyze = repos_list
        else:
            repos_to_analyze = repos_list[:limit]

        total_to_analyze = len(repos_to_analyze)

        if total_to_analyze == 0:
            print("–ù–µ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return []

        print(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –¥–ª—è {total_to_analyze} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ (–±–∞—Ç—á–∞–º–∏ –ø–æ {batch_size})...")

        analytics = []

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –Ω–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ API
        for batch_start in range(0, total_to_analyze, batch_size):
            batch_end = min(batch_start + batch_size, total_to_analyze)
            batch_repos = repos_to_analyze[batch_start:batch_end]

            print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ {batch_start//batch_size + 1}/{(total_to_analyze + batch_size - 1)//batch_size}: {batch_start+1}-{batch_end}")

            batch_analytics = []
            for i, repo in enumerate(batch_repos):
                repo_name = repo.get("nameWithOwner")
                stars = repo.get("stargazerCount", 0)
                if repo_name:
                    print(f"  –ê–Ω–∞–ª–∏–∑ {batch_start + i + 1}/{total_to_analyze}: {repo_name} ({stars}‚≠ê)")
                    repo_analytics = self.get_repository_analytics(repo_name)
                    if "error" not in repo_analytics:
                        batch_analytics.append(repo_analytics)
                    else:
                        print(f"  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {repo_name}: {repo_analytics.get('error', 'Unknown error')}")

                    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –≤ –±–∞—Ç—á–µ
                    if i < len(batch_repos) - 1:
                        time.sleep(2.5)  # –£–≤–µ–ª–∏—á–µ–Ω–Ω–∞—è –ø–∞—É–∑–∞ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏

            analytics.extend(batch_analytics)

            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
            if batch_end < total_to_analyze:
                batch_pause = min(batch_size * 3, 15)  # –ú–∞–∫—Å–∏–º—É–º 15 —Å–µ–∫—É–Ω–¥ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
                print(f"–ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏... ({batch_pause} —Å–µ–∫)")
                time.sleep(batch_pause)

        print(f"–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(analytics)}/{total_to_analyze} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤")
        return analytics

    def save_repository_analytics_to_csv(self, analytics: List[Dict[str, Any]], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –≤ CSV"""
        if not analytics:
            print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)

            writer.writerow(["–î–µ—Ç–∞–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤"])
            writer.writerow([])

            for i, repo in enumerate(analytics, 1):
                writer.writerow([f"=== –†–ï–ü–û–ó–ò–¢–û–†–ò–ô #{i}: {repo['basic_info']['name']} ==="])

                # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                basic = repo['basic_info']
                writer.writerow(["–ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"])
                writer.writerow(["–°–æ–∑–¥–∞–Ω", basic.get('created_at', '')[:10]])
                writer.writerow(["–û–±–Ω–æ–≤–ª–µ–Ω", basic.get('updated_at', '')[:10]])
                writer.writerow(["Push", basic.get('pushed_at', '')[:10]])
                writer.writerow(["–ê—Ä—Ö–∏–≤", "–î–∞" if basic.get('is_archived') else "–ù–µ—Ç"])
                writer.writerow(["–ü—Ä–∏–≤–∞—Ç–Ω—ã–π", "–î–∞" if basic.get('is_private') else "–ù–µ—Ç"])
                writer.writerow(["–§–æ—Ä–∫", "–î–∞" if basic.get('is_fork') else "–ù–µ—Ç"])
                writer.writerow([])

                # –ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å
                pop = repo['popularity']
                writer.writerow(["–ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å"])
                writer.writerow(["–ó–≤–µ–∑–¥—ã", pop.get('stars', 0)])
                writer.writerow(["–§–æ—Ä–∫–∏", pop.get('forks', 0)])
                writer.writerow(["Watchers", pop.get('watchers', 0)])
                writer.writerow([])

                # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
                act = repo['activity']
                writer.writerow(["–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å"])
                writer.writerow(["–ö–æ–º–º–∏—Ç—ã", act.get('total_commits', 0)])
                writer.writerow(["Issues", act.get('issues_total', 0)])
                writer.writerow(["PRs", act.get('pull_requests_total', 0)])
                writer.writerow(["Releases", act.get('releases_total', 0)])
                writer.writerow(["Tags", act.get('tags_total', 0)])
                writer.writerow([])

                # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                tech = repo['technical']
                writer.writerow(["–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"])
                writer.writerow(["–û—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫", tech.get('primary_language', '')])
                writer.writerow(["–†–∞–∑–º–µ—Ä (KB)", tech.get('disk_usage_kb', 0)])
                writer.writerow(["–õ–∏—Ü–µ–Ω–∑–∏—è", tech.get('license', '')])
                writer.writerow(["–ö–æ–ª–ª–∞–±–æ—Ä–∞—Ç–æ—Ä—ã", tech.get('collaborators', 0)])
                writer.writerow(["–ö–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä—ã", tech.get('contributors', 0)])
                writer.writerow(["–£—è–∑–≤–∏–º–æ—Å—Ç–∏", tech.get('vulnerabilities', 0)])
                writer.writerow([])

                # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è
                ratios = repo.get('ratios', {})
                writer.writerow(["–ú–µ—Ç—Ä–∏–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"])
                writer.writerow(["–§–æ—Ä–∫–∏/–ó–≤–µ–∑–¥—ã", ratios.get('forks_to_stars_ratio', 0)])
                writer.writerow(["Issues/–ó–≤–µ–∑–¥—ã", ratios.get('issues_to_stars_ratio', 0)])
                writer.writerow(["Activity Score", ratios.get('activity_score', 0)])
                writer.writerow([])

                # –í–æ–∑—Ä–∞—Å—Ç
                age = repo.get('age', {})
                if age:
                    writer.writerow(["–í–æ–∑—Ä–∞—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞"])
                    writer.writerow(["–î–Ω–∏", age.get('days', 0)])
                    writer.writerow(["–ú–µ—Å—è—Ü—ã", age.get('months', 0)])
                    writer.writerow(["–ì–æ–¥—ã", age.get('years', 0)])
                    writer.writerow([])

                # –Ø–∑—ã–∫–∏
                languages = repo.get('languages', {}).get('languages', {})
                if languages:
                    writer.writerow(["–Ø–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è"])
                    for lang, data in languages.items():
                        writer.writerow([lang, f"{data['percentage']}%", f"{round(data['bytes']/1024, 1)} KB"])
                    writer.writerow([])

                # –¢–µ–º—ã
                topics = repo.get('topics', [])
                if topics:
                    writer.writerow(["–¢–µ–º—ã/–¢—ç–≥–∏"])
                    writer.writerow([", ".join(topics)])
                    writer.writerow([])

                writer.writerow([])  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è–º–∏

        print(f"–î–µ—Ç–∞–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {filename}")

    def get_starred_repositories_analysis(self) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–º–µ—Ç–∏–ª –∑–≤–µ–∑–¥–æ—á–∫–æ–π
        """
        print("–ê–Ω–∞–ª–∏–∑ starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤...")

        starred = []
        cursor = None

        while True:
            query = """
            query($username: String!, $after: String) {
              user(login: $username) {
                starredRepositories(first: 100, after: $after, orderBy: {field: STARRED_AT, direction: DESC}) {
                  nodes {
                    nameWithOwner
                    description
                    stargazerCount
                    forkCount
                    primaryLanguage {
                      name
                    }
                    createdAt
                    updatedAt
                    owner {
                      login
                      __typename
                    }
                    repositoryTopics(first: 5) {
                      nodes {
                        topic {
                          name
                        }
                      }
                    }
                  }
                  pageInfo {
                    hasNextPage
                    endCursor
                  }
                }
              }
            }
            """

            variables = {
                "username": self.username,
                "after": cursor
            }

            result = self._make_graphql_request(query, variables)

            if not result.get("user") or not result["user"].get("starredRepositories"):
                break

            repos = result["user"]["starredRepositories"]
            page_repos = repos["nodes"]
            starred.extend(page_repos)

            print(f"–ü–æ—Ä—Ü–∏—è: –Ω–∞–π–¥–µ–Ω–æ {len(page_repos)} starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ (–≤—Å–µ–≥–æ: {len(starred)})")

            # –£–±–∏—Ä–∞–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ, —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
            if not repos["pageInfo"]["hasNextPage"]:
                break

            cursor = repos["pageInfo"]["endCursor"]

            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            time.sleep(0.5)

        print(f"–í—Å–µ–≥–æ starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {len(starred)}")

        # –ê–Ω–∞–ª–∏–∑ starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
        analysis = self._analyze_starred_repositories(starred)

        return {
            "starred_repositories": starred,
            "analysis": analysis
        }

    def _analyze_starred_repositories(self, starred: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""

        if not starred:
            return {"error": "–ù–µ—Ç starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"}

        # –ê–Ω–∞–ª–∏–∑ –ø–æ —è–∑—ã–∫–∞–º
        languages = {}
        for repo in starred:
            lang = repo.get('primaryLanguage', {}).get('name', 'Unknown') if repo.get('primaryLanguage') else 'Unknown'
            languages[lang] = languages.get(lang, 0) + 1

        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –≤–ª–∞–¥–µ–ª—å—Ü–µ–≤
        owner_types = {}
        for repo in starred:
            owner_type = repo.get('owner', {}).get('__typename', 'Unknown')
            owner_types[owner_type] = owner_types.get(owner_type, 0) + 1

        # –ê–Ω–∞–ª–∏–∑ –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ (–∑–≤–µ–∑–¥—ã)
        popularity_ranges = {
            "0-10": 0,
            "11-100": 0,
            "101-1000": 0,
            "1001-10000": 0,
            "10000+": 0
        }

        for repo in starred:
            stars = repo.get('stargazerCount', 0)
            if stars <= 10:
                popularity_ranges["0-10"] += 1
            elif stars <= 100:
                popularity_ranges["11-100"] += 1
            elif stars <= 1000:
                popularity_ranges["101-1000"] += 1
            elif stars <= 10000:
                popularity_ranges["1001-10000"] += 1
            else:
                popularity_ranges["10000+"] += 1

        # –¢–æ–ø —Ç–µ–º
        topics = {}
        for repo in starred:
            repo_topics = repo.get('repositoryTopics', {}).get('nodes', [])
            for topic_node in repo_topics:
                topic_name = topic_node.get('topic', {}).get('name', '')
                if topic_name:
                    topics[topic_name] = topics.get(topic_name, 0) + 1

        # –í—Å–µ starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –¥–∞—Ç–µ (—É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ –∑–∞–ø—Ä–æ—Å–µ)
        all_starred_sorted = starred

        return {
            "total_starred": len(starred),
            "languages": dict(sorted(languages.items(), key=lambda x: x[1], reverse=True)),
            "owner_types": owner_types,
            "popularity_distribution": popularity_ranges,
            "top_topics": dict(sorted(topics.items(), key=lambda x: x[1], reverse=True)[:20]),
            "all_starred_repos": [
                {
                    "name": repo.get('nameWithOwner', ''),
                    "stars": repo.get('stargazerCount', 0),
                    "language": repo.get('primaryLanguage', {}).get('name') if repo.get('primaryLanguage') else None,
                    "description": repo.get('description', '')[:150] if repo.get('description') else '',
                    "created_at": repo.get('createdAt', ''),
                    "owner_type": repo.get('owner', {}).get('__typename', 'Unknown') if repo.get('owner') else 'Unknown'
                }
                for repo in all_starred_sorted
            ]
        }

    def get_repository_contributors_analysis(self, repo_name: str) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
        """
        print(f"–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤ –¥–ª—è {repo_name}...")

        try:
            owner, name = repo_name.split('/', 1)
        except ValueError:
            return {"error": f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è: {repo_name}"}

        query = """
        query($owner: String!, $name: String!) {
          repository(owner: $owner, name: $name) {
            collaborators(first: 20) {
              nodes {
                login
                name
                company
                location
                contributions
              }
            }
            mentionableUsers(first: 50) {
              nodes {
                login
                name
                company
                location
                contributions
              }
            }
          }
        }
        """

        variables = {"owner": owner, "name": name}

        try:
            result = self._make_graphql_request(query, variables)

            if not result.get("repository"):
                return {"error": f"–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π {repo_name} –Ω–µ –Ω–∞–π–¥–µ–Ω"}

            repo = result["repository"]

            collaborators = repo.get('collaborators', {}).get('nodes', [])
            contributors = repo.get('mentionableUsers', {}).get('nodes', [])

            # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–æ–º–ø–∞–Ω–∏—è–º
            companies = {}
            locations = {}

            for user in collaborators + contributors:
                company = user.get('company', '').strip() or 'Unknown'
                location = user.get('location', '').strip() or 'Unknown'

                companies[company] = companies.get(company, 0) + 1
                locations[location] = locations.get(location, 0) + 1

            return {
                "repository": repo_name,
                "collaborators_count": len(collaborators),
                "contributors_count": len(contributors),
                "companies": dict(sorted(companies.items(), key=lambda x: x[1], reverse=True)),
                "locations": dict(sorted(locations.items(), key=lambda x: x[1], reverse=True)),
                "top_contributors": [
                    {
                        "login": user.get('login', ''),
                        "name": user.get('name', ''),
                        "company": user.get('company', ''),
                        "location": user.get('location', ''),
                        "contributions": user.get('contributions', 0)
                    }
                    for user in sorted(contributors, key=lambda x: x.get('contributions', 0), reverse=True)[:10]
                ]
            }

        except Exception as e:
            return {"error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤ {repo_name}: {str(e)}"}

    def save_starred_analysis_to_csv(self, starred_data: Dict[str, Any], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑ starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –≤ CSV"""
        if not starred_data or "analysis" not in starred_data:
            print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤")
            return

        analysis = starred_data["analysis"]

        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)

            writer.writerow(["–ê–Ω–∞–ª–∏–∑ Starred –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤"])
            writer.writerow([])
            writer.writerow(["–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"])
            writer.writerow(["–í—Å–µ–≥–æ starred", analysis.get("total_starred", 0)])
            writer.writerow([])

            # –Ø–∑—ã–∫–∏
            writer.writerow(["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —è–∑—ã–∫–∞–º"])
            writer.writerow(["–Ø–∑—ã–∫", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"])
            for lang, count in analysis.get("languages", {}).items():
                writer.writerow([lang, count])
            writer.writerow([])

            # –¢–∏–ø—ã –≤–ª–∞–¥–µ–ª—å—Ü–µ–≤
            writer.writerow(["–¢–∏–ø—ã –≤–ª–∞–¥–µ–ª—å—Ü–µ–≤"])
            writer.writerow(["–¢–∏–ø", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"])
            for owner_type, count in analysis.get("owner_types", {}).items():
                writer.writerow([owner_type, count])
            writer.writerow([])

            # –ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å
            writer.writerow(["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏"])
            writer.writerow(["–î–∏–∞–ø–∞–∑–æ–Ω –∑–≤–µ–∑–¥", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"])
            for range_name, count in analysis.get("popularity_distribution", {}).items():
                writer.writerow([range_name, count])
            writer.writerow([])

            # –¢–æ–ø —Ç–µ–º
            writer.writerow(["–¢–æ–ø —Ç–µ–º (—Ç–æ–ø-20)"])
            writer.writerow(["–¢–µ–º–∞", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"])
            for topic, count in list(analysis.get("top_topics", {}).items())[:20]:
                writer.writerow([topic, count])
            writer.writerow([])

            # –í—Å–µ starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ (–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –¥–∞—Ç–µ starred - –æ—Ç –Ω–æ–≤—ã—Ö –∫ —Å—Ç–∞—Ä—ã–º)
            writer.writerow(["–í—Å–µ starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ (–æ—Ç –Ω–æ–≤—ã—Ö –∫ —Å—Ç–∞—Ä—ã–º)"])
            writer.writerow(["#", "–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", "–ó–≤–µ–∑–¥—ã", "–Ø–∑—ã–∫", "–¢–∏–ø –≤–ª–∞–¥–µ–ª—å—Ü–∞", "–û–ø–∏—Å–∞–Ω–∏–µ"])
            for i, repo in enumerate(analysis.get("all_starred_repos", []), 1):
                writer.writerow([
                    i,
                    repo.get("name", ""),
                    repo.get("stars", 0),
                    repo.get("language", ""),
                    repo.get("owner_type", ""),
                    repo.get("description", "")[:100]
                ])

        print(f"–ê–Ω–∞–ª–∏–∑ starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {filename}")

    def save_stars_distribution_to_csv(self, repositories: List[Dict[str, Any]], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–≤–µ–∑–¥ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º –≤ CSV"""
        if not repositories:
            print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–≤–µ–∑–¥")
            return

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º –∑–≤–µ–∑–¥
        ranges = {
            "0 –∑–≤–µ–∑–¥": 0,
            "1-5 –∑–≤–µ–∑–¥": 0,
            "6-10 –∑–≤–µ–∑–¥": 0,
            "11-25 –∑–≤–µ–∑–¥": 0,
            "26-50 –∑–≤–µ–∑–¥": 0,
            "51-100 –∑–≤–µ–∑–¥": 0,
            "101-500 –∑–≤–µ–∑–¥": 0,
            "501+ –∑–≤–µ–∑–¥": 0
        }

        for repo in repositories:
            stars = repo.get('stargazerCount', 0)
            if stars == 0:
                ranges["0 –∑–≤–µ–∑–¥"] += 1
            elif stars <= 5:
                ranges["1-5 –∑–≤–µ–∑–¥"] += 1
            elif stars <= 10:
                ranges["6-10 –∑–≤–µ–∑–¥"] += 1
            elif stars <= 25:
                ranges["11-25 –∑–≤–µ–∑–¥"] += 1
            elif stars <= 50:
                ranges["26-50 –∑–≤–µ–∑–¥"] += 1
            elif stars <= 100:
                ranges["51-100 –∑–≤–µ–∑–¥"] += 1
            elif stars <= 500:
                ranges["101-500 –∑–≤–µ–∑–¥"] += 1
            else:
                ranges["501+ –∑–≤–µ–∑–¥"] += 1

        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)

            writer.writerow(["–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–≤–µ–∑–¥ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º"])
            writer.writerow([])
            writer.writerow(["–î–∏–∞–ø–∞–∑–æ–Ω", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤", "–ü—Ä–æ—Ü–µ–Ω—Ç"])

            total_repos = len(repositories)
            for range_name, count in ranges.items():
                percentage = round((count / total_repos * 100), 1) if total_repos > 0 else 0
                writer.writerow([range_name, count, f"{percentage}%"])

            writer.writerow([])
            writer.writerow(["=== –ò–ù–°–ê–ô–¢–´ ==="])

            # –ê–Ω–∞–ª–∏–∑ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
            popular_repos = sum(count for range_name, count in ranges.items() if "–∑–≤–µ–∑–¥" in range_name and not range_name.startswith("0") and not range_name.startswith("1-5"))
            popular_percentage = round((popular_repos / total_repos * 100), 1) if total_repos > 0 else 0

            writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ —Å 6+ –∑–≤–µ–∑–¥–∞–º–∏", f"{popular_repos} ({popular_percentage}%)"])

            zero_star_repos = ranges["0 –∑–≤–µ–∑–¥"]
            zero_percentage = round((zero_star_repos / total_repos * 100), 1) if total_repos > 0 else 0
            writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –±–µ–∑ –∑–≤–µ–∑–¥", f"{zero_star_repos} ({zero_percentage}%)"])

        print(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–≤–µ–∑–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {filename}")

    def get_forks_of_user_repos(self, repositories: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Ñ–æ—Ä–∫–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—Ñ–æ—Ä–∫–∏, —Å–¥–µ–ª–∞–Ω–Ω—ã–µ –¥—Ä—É–≥–∏–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏)

        Args:
            repositories: –°–ø–∏—Å–æ–∫ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            –°–ø–∏—Å–æ–∫ —Ñ–æ—Ä–∫–æ–≤ –¥—Ä—É–≥–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        """
        print("–ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ–æ—Ä–∫–æ–≤ –æ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤...")

        all_forks = []

        for repo in repositories:
            repo_name = repo.get('nameWithOwner', '')
            fork_count = repo.get('forkCount', 0)

            if fork_count == 0:
                continue

            print(f"–ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ–æ—Ä–∫–æ–≤ –¥–ª—è {repo_name} ({fork_count} —Ñ–æ—Ä–∫–æ–≤)...")

            repo_forks = []
            cursor = None

            while True:
                query = """
                query($owner: String!, $name: String!, $after: String) {
                  repository(owner: $owner, name: $name) {
                    forks(first: 100, after: $after, orderBy: {field: CREATED_AT, direction: DESC}) {
                      nodes {
                        name
                        nameWithOwner
                        url
                        createdAt
                        pushedAt
                        updatedAt
                        description
                        primaryLanguage {
                          name
                        }
                        stargazerCount
                        owner {
                          login
                        }
                      }
                      pageInfo {
                        hasNextPage
                        endCursor
                      }
                    }
                  }
                }
                """

                # –†–∞–∑–±–∏—Ä–∞–µ–º owner/name –∏–∑ nameWithOwner
                try:
                    owner, name = repo_name.split('/', 1)
                except ValueError:
                    continue

                variables = {
                    "owner": owner,
                    "name": name,
                    "after": cursor
                }

                try:
                    result = self._make_graphql_request(query, variables)

                    if not result.get("repository") or not result["repository"].get("forks"):
                        break

                    forks_data = result["repository"]["forks"]
                    page_forks = forks_data["nodes"]

                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
                    for fork in page_forks:
                        fork['_original_repo'] = repo_name
                        fork['_original_url'] = repo.get('url', '')

                    repo_forks.extend(page_forks)

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –µ—â–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    if not forks_data["pageInfo"]["hasNextPage"]:
                        break

                    cursor = forks_data["pageInfo"]["endCursor"]

                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ñ–æ—Ä–∫–æ–≤ –¥–ª—è {repo_name}: {e}")
                    break

            all_forks.extend(repo_forks)
            print(f"–ù–∞–π–¥–µ–Ω–æ {len(repo_forks)} —Ñ–æ—Ä–∫–æ–≤ –¥–ª—è {repo_name}")

        print(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —Ñ–æ—Ä–∫–æ–≤ –æ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {len(all_forks)}")
        return all_forks

    def save_forks_of_user_repos_to_csv(self, forks: List[Dict[str, Any]], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–æ—Ä–∫–∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –≤ CSV —Ñ–∞–π–ª"""
        if not forks:
            print("–ù–µ—Ç —Ñ–æ—Ä–∫–æ–≤ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        fieldnames = [
            'fork_name', 'fork_nameWithOwner', 'fork_createdAt', 'fork_pushedAt', 'fork_updatedAt',
            'fork_url', 'fork_description', 'fork_primaryLanguage', 'fork_stargazerCount',
            'fork_owner_login', 'original_repo', 'original_url'
        ]

        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()

            for fork in forks:
                owner = fork.get('owner', {})
                primary_language = fork.get('primaryLanguage', {})

                row = {
                    'fork_name': fork.get('name', ''),
                    'fork_nameWithOwner': fork.get('nameWithOwner', ''),
                    'fork_createdAt': fork.get('createdAt', ''),
                    'fork_pushedAt': fork.get('pushedAt', ''),
                    'fork_updatedAt': fork.get('updatedAt', ''),
                    'fork_url': fork.get('url', ''),
                    'fork_description': fork.get('description', ''),
                    'fork_primaryLanguage': primary_language.get('name', '') if primary_language else '',
                    'fork_stargazerCount': fork.get('stargazerCount', 0),
                    'fork_owner_login': owner.get('login', ''),
                    'original_repo': fork.get('_original_repo', ''),
                    'original_url': fork.get('_original_url', '')
                }
                writer.writerow(row)

        print(f"–§–æ—Ä–∫–∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

    def save_profile_stats_to_csv(self, profile_stats: Dict[str, Any], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ—Ñ–∏–ª—è –≤ CSV –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–æ—Å—Ç–∞ –∞–∫–∫–∞—É–Ω—Ç–∞"""
        if not profile_stats:
            print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ—Ñ–∏–ª—è
        basic_info = profile_stats.get("basic_info", {})
        social_stats = profile_stats.get("social_stats", {})
        contribution_stats = profile_stats.get("contribution_stats", {})

        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            writer.writerow(["GitHub Profile Growth Analytics"])
            writer.writerow([])

            # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            writer.writerow(["=== BASIC PROFILE INFO ==="])
            writer.writerow(["Metric", "Value"])
            writer.writerow(["Username", basic_info.get("login", "")])
            writer.writerow(["Name", basic_info.get("name", "")])
            writer.writerow(["Bio", basic_info.get("bio", "")])
            writer.writerow(["Company", basic_info.get("company", "")])
            writer.writerow(["Location", basic_info.get("location", "")])
            writer.writerow(["Website", basic_info.get("website", "")])
            writer.writerow(["Email", basic_info.get("email", "")])
            writer.writerow(["Twitter", basic_info.get("twitter", "")])
            writer.writerow(["Profile Created", basic_info.get("created_at", "")])
            writer.writerow(["Last Updated", basic_info.get("updated_at", "")])
            writer.writerow([])

            # –°–æ—Ü–∏–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            writer.writerow(["=== SOCIAL STATISTICS ==="])
            writer.writerow(["Metric", "Value"])
            writer.writerow(["Followers", social_stats.get("followers", 0)])
            writer.writerow(["Following", social_stats.get("following", 0)])
            writer.writerow(["Public Repositories", social_stats.get("repositories", 0)])
            writer.writerow(["Starred Repositories", social_stats.get("starred_repos", 0)])
            writer.writerow(["Contributed To", social_stats.get("contributed_to", 0)])
            writer.writerow([])

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ü–∏–π
            writer.writerow(["=== CONTRIBUTION STATISTICS ==="])
            writer.writerow(["Metric", "Value"])
            writer.writerow(["Total Issues Created", contribution_stats.get("total_issues", 0)])
            writer.writerow(["Total Pull Requests", contribution_stats.get("total_pull_requests", 0)])
            writer.writerow(["Total Commits", contribution_stats.get("total_commits", 0)])
            writer.writerow(["Issue Contributions", contribution_stats.get("total_issue_contributions", 0)])
            writer.writerow(["PR Contributions", contribution_stats.get("total_pr_contributions", 0)])
            writer.writerow(["PR Review Contributions", contribution_stats.get("total_pr_review_contributions", 0)])
            writer.writerow(["Repository Contributions", contribution_stats.get("total_repo_contributions", 0)])
            writer.writerow(["Contributions This Year", contribution_stats.get("total_contributions_this_year", 0)])
            writer.writerow([])

        print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ—Ñ–∏–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {filename}")

    def save_languages_to_csv(self, languages: Dict[str, Any], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —è–∑—ã–∫–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –≤ CSV"""
        if not languages:
            print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —è–∑—ã–∫–∞—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)

            writer.writerow(["Programming Languages Statistics"])
            writer.writerow([])
            writer.writerow(["Language", "Percentage", "Total Bytes"])
            writer.writerow([])

            by_percentage = languages.get("by_percentage", {})
            by_bytes = languages.get("by_bytes", {})

            for lang in by_percentage.keys():
                percentage = by_percentage.get(lang, 0)
                bytes_count = by_bytes.get(lang, 0)
                writer.writerow([lang, f"{percentage}%", bytes_count])

            writer.writerow([])
            writer.writerow(["Total Languages", languages.get("total_languages", 0)])

        print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —è–∑—ã–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {filename}")

    def save_top_repos_to_csv(self, top_repos: List[Dict[str, Any]], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–æ–ø —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –≤ CSV"""
        if not top_repos:
            print("–ù–µ—Ç —Ç–æ–ø —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)

            writer.writerow(["Top Repositories by Stars"])
            writer.writerow([])
            writer.writerow(["Repository", "Stars", "Forks", "Language", "Created", "Updated", "Archived"])

            for repo in top_repos:
                writer.writerow([
                    repo.get("name", ""),
                    repo.get("stars", 0),
                    repo.get("forks", 0),
                    repo.get("language", ""),
                    repo.get("created_at", "")[:10] if repo.get("created_at") else "",
                    repo.get("updated_at", "")[:10] if repo.get("updated_at") else "",
                    "Yes" if repo.get("is_archived") else "No"
                ])

        print(f"–¢–æ–ø —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {filename}")

    def save_activity_trends_to_csv(self, activity_trends: Dict[str, Any], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç—Ä–µ–Ω–¥—ã –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≤ CSV"""
        if not activity_trends:
            print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ–± –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)

            writer.writerow(["Activity Trends & Growth Analytics"])
            writer.writerow([])
            writer.writerow(["Metric", "Value"])
            writer.writerow(["Total Contributions (Last Year)", activity_trends.get("total_contributions_last_year", 0)])
            writer.writerow(["Active Days (Last Year)", activity_trends.get("active_days_last_year", 0)])
            writer.writerow(["Average Weekly Contributions", activity_trends.get("average_weekly_contributions", 0)])
            writer.writerow(["Average Daily Contributions", activity_trends.get("average_daily_contributions", 0)])
            writer.writerow(["Max Daily Contributions", activity_trends.get("max_daily_contributions", 0)])
            writer.writerow(["Most Active Day", activity_trends.get("most_active_day", "")])
            writer.writerow(["Consistency Score (%)", activity_trends.get("consistency_score", 0)])
            writer.writerow([])

            # –ú–µ—Å—è—á–Ω—ã–µ –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ü–∏–∏
            writer.writerow(["Monthly Contributions"])
            writer.writerow(["Month", "Contributions"])
            monthly = activity_trends.get("monthly_contributions", {})
            for month, count in monthly.items():
                writer.writerow([month, count])

        print(f"–¢—Ä–µ–Ω–¥—ã –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

    def unstar_all_repositories(self, confirm: bool = False, batch_size: int = 10) -> Dict[str, Any]:
        """
        –£–¥–∞–ª–∏—Ç—å –∑–≤–µ–∑–¥—ã —Å–æ –í–°–ï–• starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤

        Args:
            confirm: –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ (–¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)
            batch_size: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞ —Ä–∞–∑

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏
        """
        if not confirm:
            print("‚ùå –û–ü–ê–°–ù–ê–Ø –û–ü–ï–†–ê–¶–ò–Ø!")
            print("–≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞ —É–¥–∞–ª–∏—Ç –í–°–ï –≤–∞—à–∏ starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏!")
            print("–≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ –ù–ï–õ–¨–ó–Ø –æ—Ç–º–µ–Ω–∏—Ç—å!")
            print("")
            print("–î–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –¥–æ–±–∞–≤—å—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä confirm=True")
            print("–ü—Ä–∏–º–µ—Ä: collector.unstar_all_repositories(confirm=True)")
            return {"error": "–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ", "unstarred": 0}

        print("‚ö†Ô∏è  –ù–ê–ß–ò–ù–ê–ï–ú –û–ü–ï–†–ê–¶–ò–Æ –£–î–ê–õ–ï–ù–ò–Ø –í–°–ï–• –ó–í–ï–ó–î!")
        print("–≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–µ–ª—å–∑—è –æ—Ç–º–µ–Ω–∏—Ç—å!")

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
        starred_analysis = self.get_starred_repositories_analysis()
        starred_repos = starred_analysis.get("analysis", {}).get("all_starred_repos", [])

        if not starred_repos:
            return {"message": "–ù–µ—Ç starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è", "unstarred": 0}

        total_to_unstar = len(starred_repos)
        print(f"–ù–∞–π–¥–µ–Ω–æ {total_to_unstar} starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è")

        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º
        backup_file = f"starred_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(backup_file, 'w', encoding='utf-8') as f:
            json.dump(starred_repos, f, indent=2, ensure_ascii=False)
        print(f"üìÅ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {backup_file}")

        unstarred_count = 0
        errors = []

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏
        for i in range(0, total_to_unstar, batch_size):
            batch_end = min(i + batch_size, total_to_unstar)
            batch_repos = starred_repos[i:batch_end]

            print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ {i//batch_size + 1}/{(total_to_unstar + batch_size - 1)//batch_size}: {i+1}-{batch_end}")

            for j, repo in enumerate(batch_repos):
                repo_name = repo.get("name", "")
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º REST API –¥–ª—è unstar
                    owner, name = repo_name.split('/', 1)
                    url = f"{self.base_url}/user/starred/{owner}/{name}"

                    response = self.session.delete(url)

                    if response.status_code == 204:
                        unstarred_count += 1
                        print(f"  ‚úÖ {i + j + 1}/{total_to_unstar}: {repo_name}")
                    elif response.status_code == 403:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ rate limit
                        remaining = response.headers.get("X-RateLimit-Remaining", "unknown")
                        reset_time = response.headers.get("X-RateLimit-Reset", "unknown")

                        if remaining == "0":
                            # Rate limit exceeded
                            reset_timestamp = int(reset_time) if reset_time.isdigit() else 0
                            wait_time = max(reset_timestamp - int(time.time()), 60)
                            print(f"  ‚è≥ Rate limit! –ñ–¥–µ–º {wait_time} —Å–µ–∫ –¥–æ {time.strftime('%H:%M:%S', time.localtime(reset_timestamp))}")
                            time.sleep(wait_time)
                            # –ü–æ–≤—Ç–æ—Ä—è–µ–º –ø–æ–ø—ã—Ç–∫—É –ø–æ—Å–ª–µ –æ–∂–∏–¥–∞–Ω–∏—è
                            response = self.session.delete(url)
                            if response.status_code == 204:
                                unstarred_count += 1
                                print(f"  ‚úÖ {i + j + 1}/{total_to_unstar}: {repo_name} (–ø–æ—Å–ª–µ –æ–∂–∏–¥–∞–Ω–∏—è)")
                                continue

                        # –ï—Å–ª–∏ –Ω–µ rate limit, —Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ —Å –ø—Ä–∞–≤–∞–º–∏ —Ç–æ–∫–µ–Ω–∞
                        error_msg = f"403 Forbidden - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ —Ç–æ–∫–µ–Ω–∞. –¢—Ä–µ–±—É–µ—Ç—Å—è scope 'user' –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è–º–∏"
                        errors.append(f"{repo_name}: {error_msg}")
                        print(f"  ‚ùå {i + j + 1}/{total_to_unstar}: {repo_name} - {error_msg}")

                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                        print(f"      –û—Å—Ç–∞–ª–æ—Å—å –∑–∞–ø—Ä–æ—Å–æ–≤: {remaining}")
                        print(f"      –°–±—Ä–æ—Å –ª–∏–º–∏—Ç–∞: {reset_time}")
                        if response.text:
                            print(f"      –û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞: {response.text[:200]}")

                    elif response.status_code == 404:
                        error_msg = f"404 Not Found - —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π {repo_name} –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ —É–∂–µ –Ω–µ starred"
                        errors.append(f"{repo_name}: {error_msg}")
                        print(f"  ‚ö†Ô∏è  {i + j + 1}/{total_to_unstar}: {repo_name} - {error_msg}")

                    else:
                        error_msg = f"HTTP {response.status_code}: {response.text[:100] if response.text else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'}"
                        errors.append(f"{repo_name}: {error_msg}")
                        print(f"  ‚ùå {i + j + 1}/{total_to_unstar}: {repo_name} - {error_msg}")

                except Exception as e:
                    error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {repo_name}: {str(e)}"
                    errors.append(error_msg)
                    print(f"  ‚ùå {i + j + 1}/{total_to_unstar}: {repo_name} - {error_msg}")

            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
            if batch_end < total_to_unstar:
                pause_time = min(batch_size, 30)  # –ú–∞–∫—Å–∏–º—É–º 30 —Å–µ–∫—É–Ω–¥
                print(f"–ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏... ({pause_time} —Å–µ–∫)")
                time.sleep(pause_time)

        result = {
            "total_attempted": total_to_unstar,
            "successfully_unstarred": unstarred_count,
            "errors_count": len(errors),
            "errors": errors[:10],  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10 –æ—à–∏–±–æ–∫
            "backup_file": backup_file,
            "success_rate": round((unstarred_count / total_to_unstar) * 100, 1) if total_to_unstar > 0 else 0
        }

        print("\nüéØ –û–ü–ï–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–æ –∑–≤–µ–∑–¥: {unstarred_count}/{total_to_unstar}")
        print(f"‚ùå –û—à–∏–±–æ–∫: {len(errors)}")
        print(f"üìÅ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup_file}")

        return result

    def check_repository_files(self, repo_owner: str, repo_name: str) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ LICENSE –∏ README —á–µ—Ä–µ–∑ GitHub Contents API
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ñ–∞–π–ª–æ–≤ –ª–∏—Ü–µ–Ω–∑–∏–∏
            license_files = ["LICENSE", "LICENSE.md", "LICENSE.txt", "LICENCE", "COPYING", "COPYING.md"]
            has_license = False
            license_found = None

            for license_file in license_files:
                license_url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{license_file}"
                license_response = self.session.get(license_url)
                if license_response.status_code == 200:
                    has_license = True
                    license_found = license_file
                    break

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã README —Ñ–∞–π–ª–æ–≤
            readme_files = ["README.md", "README.rst", "README.txt", "README", "readme.md", "Readme.md"]
            has_readme = False
            readme_found = None

            for readme_file in readme_files:
                readme_url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{readme_file}"
                readme_response = self.session.get(readme_url)
                if readme_response.status_code == 200:
                    has_readme = True
                    readme_found = readme_file
                    break

            return {
                "has_license_file": has_license,
                "license_file": license_found,
                "has_readme_file": has_readme,
                "readme_file": readme_found
            }
        except Exception as e:
            return {
                "has_license_file": False,
                "has_readme_file": False,
                "error": str(e)
            }

    def analyze_repository_quality(self) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ - –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –≤–∞–∂–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        """
        print("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤...")

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_repos = self.get_user_repositories()

        if not user_repos:
            return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"}

        quality_issues = {
            "missing_description": [],
            "missing_license": [],
            "missing_topics": [],
            "missing_readme": [],
            "low_quality_score": []
        }

        total_repos = len(user_repos)
        analyzed = 0

        print(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {total_repos} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤...")

        for repo in user_repos:
            repo_name = repo.get("nameWithOwner", "")
            analyzed += 1

            print(f"  {analyzed}/{total_repos}: {repo_name}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
            if not repo.get("description") or repo.get("description", "").strip() == "":
                quality_issues["missing_description"].append({
                    "repo": repo_name,
                    "url": repo.get("url", ""),
                    "stars": repo.get("stargazerCount", 0),
                    "updated": repo.get("updatedAt", "")
                })

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏—Ü–µ–Ω–∑–∏—é (GraphQL + –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤)
            has_license_graphql = bool(repo.get("licenseInfo"))

            if not has_license_graphql:
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ Contents API
                try:
                    owner, name = repo_name.split('/', 1)
                    files_check = self.check_repository_files(owner, name)
                    has_license_file = files_check.get("has_license_file", False)

                    if not has_license_file:
                        quality_issues["missing_license"].append({
                            "repo": repo_name,
                            "url": repo.get("url", ""),
                            "stars": repo.get("stargazerCount", 0),
                            "updated": repo.get("updatedAt", "")
                        })
                except Exception as e:
                    # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∞–π–ª—ã, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –ª–∏—Ü–µ–Ω–∑–∏–∏ –Ω–µ—Ç
                    quality_issues["missing_license"].append({
                        "repo": repo_name,
                        "url": repo.get("url", ""),
                        "stars": repo.get("stargazerCount", 0),
                        "updated": repo.get("updatedAt", "")
                    })

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ø–∏–∫–∏/—Ç–µ–≥–∏ (GraphQL)
            repository_topics = repo.get("repositoryTopics", {}).get("nodes", [])
            has_topics_graphql = bool(repository_topics and len(repository_topics) > 0)

            if not has_topics_graphql:
                quality_issues["missing_topics"].append({
                    "repo": repo_name,
                    "url": repo.get("url", ""),
                    "stars": repo.get("stargazerCount", 0),
                    "updated": repo.get("updatedAt", "")
                })

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º README (—á–µ—Ä–µ–∑ Contents API)
            try:
                owner, name = repo_name.split('/', 1)
                files_check = self.check_repository_files(owner, name)
                has_readme_file = files_check.get("has_readme_file", False)

                if not has_readme_file:
                    quality_issues["missing_readme"].append({
                        "repo": repo_name,
                        "url": repo.get("url", ""),
                        "stars": repo.get("stargazerCount", 0),
                        "size_kb": repo.get("diskUsage", 0),
                        "updated": repo.get("updatedAt", "")
                    })
            except Exception as e:
                # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–º–µ—Ä –∫–∞–∫ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä
                size_kb = repo.get("diskUsage", 0)
                if size_kb < 10:  # –ú–µ–Ω–µ–µ 10KB - –≤–æ–∑–º–æ–∂–Ω–æ –Ω–µ—Ç README
                    quality_issues["missing_readme"].append({
                        "repo": repo_name,
                        "url": repo.get("url", ""),
                        "stars": repo.get("stargazerCount", 0),
                        "size_kb": size_kb,
                        "updated": repo.get("updatedAt", "")
                    })

        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = {
            "total_repositories": total_repos,
            "analyzed_repositories": analyzed,
            "quality_score": round((1 - sum(len(v) for v in quality_issues.values()) / (total_repos * 4)) * 100, 1),
            "issues_summary": {
                "missing_description": len(quality_issues["missing_description"]),
                "missing_license": len(quality_issues["missing_license"]),
                "missing_topics": len(quality_issues["missing_topics"]),
                "missing_readme": len(quality_issues["missing_readme"])
            }
        }

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ —Å –Ω–∏–∑–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º (–±–æ–ª–µ–µ 2 –ø—Ä–æ–±–ª–µ–º)
        for repo in user_repos:
            repo_name = repo.get("nameWithOwner", "")
            issues_count = sum(1 for issue_list in quality_issues.values()
                             for issue in issue_list if issue["repo"] == repo_name)

            if issues_count >= 2:
                quality_issues["low_quality_score"].append({
                    "repo": repo_name,
                    "url": repo.get("url", ""),
                    "stars": repo.get("stargazerCount", 0),
                    "issues_count": issues_count,
                    "updated": repo.get("updatedAt", "")
                })

        result = {
            "statistics": stats,
            "quality_issues": quality_issues
        }

        print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê –ö–ê–ß–ï–°–¢–í–ê:")
        print(f"–í—Å–µ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {stats['total_repositories']}")
        print(".1f")
        print(f"–ë–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è: {stats['issues_summary']['missing_description']}")
        print(f"–ë–µ–∑ –ª–∏—Ü–µ–Ω–∑–∏–∏: {stats['issues_summary']['missing_license']}")
        print(f"–ë–µ–∑ —Ç–µ–≥–æ–≤: {stats['issues_summary']['missing_topics']}")
        print(f"–í–æ–∑–º–æ–∂–Ω–æ –±–µ–∑ README: {stats['issues_summary']['missing_readme']}")
        print(f"–ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (2+ –ø—Ä–æ–±–ª–µ–º): {len(quality_issues['low_quality_score'])}")

        return result

    def save_quality_analysis_to_csv(self, quality_data: Dict[str, Any], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –≤ CSV"""
        if not quality_data or "quality_issues" not in quality_data:
            print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞")
            return

        stats = quality_data.get("statistics", {})
        issues = quality_data.get("quality_issues", {})

        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            writer.writerow(["–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤"])
            writer.writerow([])

            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            writer.writerow(["–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"])
            writer.writerow(["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", "–ó–Ω–∞—á–µ–Ω–∏–µ"])
            writer.writerow(["–í—Å–µ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤", stats.get("total_repositories", 0)])
            writer.writerow(["–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ", stats.get("analyzed_repositories", 0)])
            writer.writerow(["–û–±—â–∏–π –±–∞–ª–ª –∫–∞—á–µ—Å—Ç–≤–∞", ".1f"])
            writer.writerow([])

            # –ü—Ä–æ–±–ª–µ–º—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            writer.writerow(["–ü—Ä–æ–±–ª–µ–º—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"])
            writer.writerow(["–ö–∞—Ç–µ–≥–æ—Ä–∏—è", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", "–ü—Ä–æ—Ü–µ–Ω—Ç"])
            issues_summary = stats.get("issues_summary", {})
            total = stats.get("total_repositories", 1)

            categories = [
                ("–ë–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è", "missing_description"),
                ("–ë–µ–∑ –ª–∏—Ü–µ–Ω–∑–∏–∏", "missing_license"),
                ("–ë–µ–∑ —Ç–µ–≥–æ–≤", "missing_topics"),
                ("–í–æ–∑–º–æ–∂–Ω–æ –±–µ–∑ README", "missing_readme")
            ]

            for category_name, category_key in categories:
                count = issues_summary.get(category_key, 0)
                percentage = round((count / total) * 100, 1) if total > 0 else 0
                writer.writerow([category_name, count, f"{percentage}%"])
            writer.writerow([])

            # –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è
            if issues.get("missing_description"):
                writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ë–ï–ó –û–ü–ò–°–ê–ù–ò–Ø"])
                writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", "–ó–≤–µ–∑–¥—ã", "–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ", "URL"])
                for repo in sorted(issues["missing_description"], key=lambda x: x.get("stars", 0), reverse=True):
                    writer.writerow([
                        repo.get("repo", ""),
                        repo.get("stars", 0),
                        repo.get("updated", "")[:10] if repo.get("updated") else "",
                        repo.get("url", "")
                    ])
                writer.writerow([])

            # –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –±–µ–∑ –ª–∏—Ü–µ–Ω–∑–∏–∏
            if issues.get("missing_license"):
                writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ë–ï–ó –õ–ò–¶–ï–ù–ó–ò–ò"])
                writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", "–ó–≤–µ–∑–¥—ã", "–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ", "URL"])
                for repo in sorted(issues["missing_license"], key=lambda x: x.get("stars", 0), reverse=True):
                    writer.writerow([
                        repo.get("repo", ""),
                        repo.get("stars", 0),
                        repo.get("updated", "")[:10] if repo.get("updated") else "",
                        repo.get("url", "")
                    ])
                writer.writerow([])

            # –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –±–µ–∑ —Ç–µ–≥–æ–≤
            if issues.get("missing_topics"):
                writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ë–ï–ó –¢–ï–ì–û–í"])
                writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", "–ó–≤–µ–∑–¥—ã", "–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ", "URL"])
                for repo in sorted(issues["missing_topics"], key=lambda x: x.get("stars", 0), reverse=True):
                    writer.writerow([
                        repo.get("repo", ""),
                        repo.get("stars", 0),
                        repo.get("updated", "")[:10] if repo.get("updated") else "",
                        repo.get("url", "")
                    ])
                writer.writerow([])

            # –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ —Å –Ω–∏–∑–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º
            if issues.get("low_quality_score"):
                writer.writerow(["–ù–ò–ó–ö–û–ï –ö–ê–ß–ï–°–¢–í–û (2+ –ü–†–û–ë–õ–ï–ú–´)"])
                writer.writerow(["–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", "–ó–≤–µ–∑–¥—ã", "–ü—Ä–æ–±–ª–µ–º", "–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ", "URL"])
                for repo in sorted(issues["low_quality_score"], key=lambda x: x.get("issues_count", 0), reverse=True):
                    writer.writerow([
                        repo.get("repo", ""),
                        repo.get("stars", 0),
                        repo.get("issues_count", 0),
                        repo.get("updated", "")[:10] if repo.get("updated") else "",
                        repo.get("url", "")
                    ])
                writer.writerow([])

            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            writer.writerow(["–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –£–õ–£–ß–®–ï–ù–ò–Ø"])
            writer.writerow(["1. –î–æ–±–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏—è –∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è–º - —ç—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –ø–æ–Ω—è—Ç—å, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –ø—Ä–æ–µ–∫—Ç"])
            writer.writerow(["2. –í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â—É—é –ª–∏—Ü–µ–Ω–∑–∏—é (MIT, Apache 2.0, GPL –∏ —Ç.–¥.)"])
            writer.writerow(["3. –î–æ–±–∞–≤—å—Ç–µ —Ç–µ–≥–∏/—Ç–æ–ø–∏–∫–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏"])
            writer.writerow(["4. –°–æ–∑–¥–∞–π—Ç–µ README.md —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é"])
            writer.writerow(["5. –ù–∞—á–Ω–∏—Ç–µ —Å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤, —É –∫–æ—Ç–æ—Ä—ã—Ö –±–æ–ª—å—à–µ –∑–≤–µ–∑–¥ - –æ–Ω–∏ –¥–∞—é—Ç –±–æ–ª—å—à–∏–π —ç—Ñ—Ñ–µ–∫—Ç"])

        print(f"–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {filename}")

    def collect_all_data(self):
        """–°–æ–±—Ä–∞—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ —Ñ–∞–π–ª—ã"""
        print(f"–ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {self.username}")

        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ—Ñ–∏–ª—è –¥–ª—è —Ä–æ—Å—Ç–∞ –∞–∫–∫–∞—É–Ω—Ç–∞
        profile_stats = self.get_user_profile_stats()

        # –ü–æ–ª—É—á–∞–µ–º —Ñ–æ—Ä–∫–∏ (—Ñ–æ—Ä–∫–∏ –¥—Ä—É–≥–∏—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤)
        forks = self.get_all_forks()

        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
        user_repos = self.get_user_repositories()

        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –∑–≤–µ–∑–¥–∞–º
        repos_stars_sorted = self.get_repositories_stars_sorted()

        # –ü–æ–ª—É—á–∞–µ–º –∞–Ω–∞–ª–∏–∑ starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
        starred_analysis = self.get_starred_repositories_analysis()

        # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É –ø–æ –≤—Å–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è–º —Å –∑–≤–µ–∑–¥–∞–º–∏
        repos_with_stars = [repo for repo in repos_stars_sorted if repo.get('stargazerCount', 0) > 0]
        all_repos_analytics = self.get_top_repositories_analytics(repos_with_stars, limit=None, batch_size=3)

        # –ü–æ–ª—É—á–∞–µ–º —Ñ–æ—Ä–∫–∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
        forks_of_user_repos = self.get_forks_of_user_repos(user_repos)

        # –ü–æ–ª—É—á–∞–µ–º issues
        issues = self.get_all_issues()

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
        quality_analysis = self.analyze_repository_quality()

        # –ì–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        data = {
            "username": self.username,
            "collected_at": datetime.now().isoformat(),
            "profile_stats": profile_stats,  # —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è —Ä–æ—Å—Ç–∞ –∞–∫–∫–∞—É–Ω—Ç–∞
            "starred_analysis": starred_analysis,  # –∞–Ω–∞–ª–∏–∑ starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
            "quality_analysis": quality_analysis,  # –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
            "forks": forks,  # —Ñ–æ—Ä–∫–∏ –¥—Ä—É–≥–∏—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
            "user_repositories": user_repos,  # —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
            "repositories_stars_sorted": repos_stars_sorted,  # —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –∑–≤–µ–∑–¥–∞–º
            "all_repositories_analytics": all_repos_analytics,  # –¥–µ—Ç–∞–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –≤—Å–µ—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ —Å –∑–≤–µ–∑–¥–∞–º–∏
            "forks_of_user_repos": forks_of_user_repos,  # —Ñ–æ—Ä–∫–∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
            "issues": issues,
            "summary": {
                "total_forks": len(forks),  # —Ñ–æ—Ä–∫–∏ –¥—Ä—É–≥–∏—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
                "total_user_repos": len(user_repos),  # —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
                "total_repos_stars_sorted": len(repos_stars_sorted),  # —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ø–æ –∑–≤–µ–∑–¥–∞–º
                "total_forks_of_user_repos": len(forks_of_user_repos),  # —Ñ–æ—Ä–∫–∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
                "total_issues": len(issues),
                "open_issues": len([i for i in issues if i.get('state') == 'OPEN']),
                "closed_issues": len([i for i in issues if i.get('state') == 'CLOSED']),
                "total_stars_all_repos": sum(repo.get('stargazerCount', 0) for repo in repos_stars_sorted),
                "average_stars_per_repo": round(sum(repo.get('stargazerCount', 0) for repo in repos_stars_sorted) / len(repos_stars_sorted), 2) if repos_stars_sorted else 0,
                "all_repos_analyzed": len(all_repos_analytics)  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
            }
        }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
        self.save_to_json(data, "github_data.json")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ—Ñ–∏–ª—è –¥–ª—è —Ä–æ—Å—Ç–∞ –∞–∫–∫–∞—É–Ω—Ç–∞
        self.save_profile_stats_to_csv(profile_stats, "github_profile_growth.csv")
        self.save_languages_to_csv(profile_stats.get("languages", {}), "github_languages.csv")
        self.save_top_repos_to_csv(profile_stats.get("top_repositories", []), "github_top_repos.csv")
        self.save_activity_trends_to_csv(profile_stats.get("activity_trends", {}), "github_activity_trends.csv")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
        self.save_starred_analysis_to_csv(starred_analysis, "github_starred_analysis.csv")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ä–∫–∏ –≤ CSV
        self.save_forks_to_csv(forks, "github_forks.csv")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –∑–≤–µ–∑–¥–∞–º
        self.save_repositories_stars_to_csv(repos_stars_sorted, "github_repos_stars_sorted.csv")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–≤–µ–∑–¥
        self.save_stars_distribution_to_csv(repos_stars_sorted, "github_stars_distribution.csv")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É –≤—Å–µ—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ —Å –∑–≤–µ–∑–¥–∞–º–∏
        self.save_repository_analytics_to_csv(all_repos_analytics, "github_top_repos_detailed_analytics.csv")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ä–∫–∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –≤ CSV
        self.save_forks_of_user_repos_to_csv(forks_of_user_repos, "github_forks_of_user_repos.csv")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º issues –≤ CSV
        self.save_issues_to_csv(issues, "github_issues.csv")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
        self.save_quality_analysis_to_csv(quality_analysis, "github_quality_analysis.csv")

        print("–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"–§–æ—Ä–∫–æ–≤ –¥—Ä—É–≥–∏—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {len(forks)}")
        print(f"–°–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {len(user_repos)}")
        print(f"–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –ø–æ –∑–≤–µ–∑–¥–∞–º: {len(repos_stars_sorted)}")
        print(f"–í—Å–µ–≥–æ –∑–≤–µ–∑–¥ –Ω–∞ –≤—Å–µ—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è—Ö: {sum(repo.get('stargazerCount', 0) for repo in repos_stars_sorted)}")
        print(f"Starred —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {starred_analysis.get('analysis', {}).get('total_starred', 0)}")
        print(f"–î–µ—Ç–∞–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –≤—Å–µ—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ —Å –∑–≤–µ–∑–¥–∞–º–∏: {len(all_repos_analytics)}")
        print(f"–§–æ—Ä–∫–æ–≤ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {len(forks_of_user_repos)}")
        print(f"Issues: {len(issues)}")
        print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ—Ñ–∏–ª—è –¥–ª—è —Ä–æ—Å—Ç–∞ –∞–∫–∫–∞—É–Ω—Ç–∞ —Å–æ–±—Ä–∞–Ω–∞!")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) > 1:
        if sys.argv[1] == '--license-manager':
            # –ó–∞–ø—É—Å–∫ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –ª–∏—Ü–µ–Ω–∑–∏–π
            token = "github_pat_1"
            if not token:
                print("‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω!")
                return

            license_manager = GitHubLicenseBatchManager(token)

            username = license_manager.get_authenticated_user()
            if not username:
                print("‚ùå –û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω.")
                return

            print(f"üë§ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å, {username}!")
            license_manager.interactive_batch_setup()
            return

        elif sys.argv[1] == '--demo-unstar':
            demo_unstar_warning()
            return

        elif sys.argv[1] == '--check-readme':
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è README —Ñ–∞–π–ª–æ–≤
            token = "github_pat_1"
            if not token:
                print("‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω!")
                return

            license_manager = GitHubLicenseBatchManager(token)

            username = license_manager.get_authenticated_user()
            if not username:
                print("‚ùå –û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω.")
                return

            print(f"üë§ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å, {username}!")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ README –≤–æ –≤—Å–µ—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è—Ö
            readme_data = license_manager.check_readme_presence(include_forks=False)
            license_manager.save_readme_check_to_csv(readme_data, "github_readme_check.csv")
            return

        elif sys.argv[1] == '--check-topics':
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–µ–≥–æ–≤ (—Ç–æ–ø–∏–∫–æ–≤)
            token = "github_pat_1"
            if not token:
                print("‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω!")
                return

            license_manager = GitHubLicenseBatchManager(token)

            username = license_manager.get_authenticated_user()
            if not username:
                print("‚ùå –û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω.")
                return

            print(f"üë§ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å, {username}!")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–µ–≥–æ–≤ –≤–æ –≤—Å–µ—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è—Ö
            topics_data = license_manager.check_topics_presence()
            license_manager.save_topics_check_to_csv(topics_data, "github_topics_check.csv")
            return

    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    token = "github_pat_1"

    if not token:
        print("GitHub Personal Access Token –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("–°–æ–∑–¥–∞–π—Ç–µ PAT –≤ GitHub (Settings ‚Üí Developer settings ‚Üí Personal access tokens)")
        print("–ò —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è GITHUB_TOKEN –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ —Ç–æ–∫–µ–Ω –Ω–∏–∂–µ:")
        token = input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à GitHub PAT: ").strip()

    if not token:
        print("–¢–æ–∫–µ–Ω –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω. –í—ã—Ö–æ–¥.")
        return

    try:
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–µ–∫—Ç–æ—Ä
        collector = GitHubDataCollector(token)

        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        collector.collect_all_data()

    except requests.exceptions.RequestException as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å GitHub API: {e}")
    except KeyboardInterrupt:
        print("\n–û–ø–µ—Ä–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")


def demo_unstar_warning():
    token = "---"
    collector = GitHubDataCollector(token)
    result = collector.unstar_all_repositories(confirm=True, batch_size=5)
    print(result)

    print("–£–¥–∞–ª–µ–Ω–∏–µ –∑–≤–µ–∑–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"–£—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–æ –∑–≤–µ–∑–¥: {result.get('successfully_unstarred', 0)}")
    print(f"–û—à–∏–±–æ–∫: {result.get('errors_count', 0)}")
    print(f"–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {result.get('backup_file', '–ù–µ —Å–æ–∑–¥–∞–Ω–∞')}")
    print(f"–£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {result.get('success_rate', 0)}%")


if __name__ == "__main__":
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) > 1 and sys.argv[1] == "--demo-unstar":
        demo_unstar_warning()
    else:
        main()
